################################# JUST THE CODE ###############################
#INITIALIZE
mkdir /workdir/hh693
cd /workdir/hh693
cp /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/* . &

#BBMAP
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
export PATH=/programs/bbmap-38.73:$PATH
for SAMPLE in "${SAMPLES[@]}"; do
	echo "$SAMPLE"
	bbduk.sh in1=$SAMPLE'_R1.fastq.gz' in2=$SAMPLE'_R2.fastq.gz' out1=$SAMPLE'_clean_R1.fastq.gz' out2=$SAMPLE'_clean_R2.fastq.gz' ref=/programs/bbmap-38.73/resources/adapters.fa maq=10 ktrim=r k=23 mink=11 hdist=1 tpe tbo >& $SAMPLE'_bbmap.log'
done

#TRINITY POST BBMAP
chmod u+x Trinity_Solidissima.sh
nohup ./Trinity_Solidissima.sh >& Trinity_Sol.log &
chmod u+x Trinity_Similis.sh
nohup ./Trinity_Similis.sh >& Trinity_Sim.log &

#SCRIPT EXAMPLE
TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
TRINITY_OUT=./trinity_out_Similis/
export PATH=/programs/jellyfish-2.2.3/bin:$PATH
export PATH=/programs/salmon-0.11.3/bin:$PATH
export PATH=/programs/bowtie2-2.3.4.3:$PATH
$TRINITY_HOME/Trinity --seqType fq \
--left Sim4_clean_R1.fastq.gz,Sim5_clean_R1.fastq.gz,Sim6_clean_R1.fastq.gz \
--right Sim4_clean_R2.fastq.gz,Sim5_clean_R2.fastq.gz,Sim6_clean_R2.fastq.gz \
--max_memory 10G  \
--CPU 11 \
--output $TRINITY_OUT

#TRIM TRINITY BY ISOFORM SELECTION
# open Trinity.fasta.gene_trans_map in excel
grep ">" trinity_out_Solidissima/Trinity.fasta > sequenceheader_Sol
# open sequenceheader_Sol in excel
# replace len= with nothing
# replace > with nothing
# copy the isoform name and length into the map excel
# make sure isoforms map
# then data > sort, column A (gene) A to Z, column C (length) Largest to Smallest
# all columns and remove duplicates from column A
# save just the list of isoforms as a .txt
makeblastdb -in Trinity.fasta -dbtype nucl -parse_seqids
blastdbcmd -db Trinity.fasta -entry_batch LongestIso_Sol.txt -out Trinity_longiso.fasta

#TRINITY QC
export BUSCO_CONFIG_FILE=/workdir/hh693/config.ini 
export PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packages 
export PATH=/programs/busco-3.1.0/scripts:$PATH 
run_BUSCO.py --in ./Trinity_iso_Sol.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOiso_Solidissima -f >& BUSCO_iso_sol.log &
blastx -query ./Trinity_iso_Sol.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sol_iso.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &
run_BUSCO.py --in ./Trinity_iso_Sol.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 8 --out BUSCOiso_Solidissima_Mollusc -f >& BUSCO_iso_moll_sol.log &
generate_plot.py -wd run_BUSCOiso_Solidissima
export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol_iso.outfmt6 Trinity_iso_Sol.fasta db_ref/uniprot_sprot.fasta
$TRINITY_HOME/util/TrinityStats.pl Trinity_iso_Sol.fasta

#BWA PREPARE REF
#Rename copy
TMP=/workdir/$USER/tmp
GATKDIR=/programs/gatk-4.1.4.0
export PATH=$GATKDIR:$PATH
gatk CreateSequenceDictionary -R Sol_ref.fa  -O Sol_ref.dict
samtools faidx Sol_ref.fa
#Index for BWA alignment
bwa index Sol_ref.fa

#BWA ALIGN
# Basic script code (change ACC):
TMP=/workdir/$USER/tmp
GATKDIR=/programs/gatk-4.1.4.0
export PATH=$GATKDIR:$PATH
ACC=Sol10
SAM=Solidissima
REFFASTA=Sol_ref.fa
bwa mem -t 11  -R "@RG\tID:${ACC}\tSM:${ACC}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA ${ACC}_clean_R1.fastq.gz ${ACC}_clean_R2.fastq.gz | samtools view -Sb -@18 -o ${ACC}_iso_output.bam -

#MARK DUPLICATES
#SWITCH TO OLD JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
ACC=Sim5
SAM=Solidissima
REFFASTA=Sol_ref.fa
gatk MarkDuplicatesSpark \
-I ${ACC}_iso_output.bam \
-O ${ACC}.sorted.dedup.bam \
-M ${ACC}.sorted.dedup.txt \
--tmp-dir $TMP \
--conf "spark.executor.cores=7" \
>& sortdedup_${ACC}.log &

#LIST OF ALL CHROMOSOMES TO DO BY REGION
grep ">" Sol_ref.fa | awk '{print $1}' | awk '{ print substr($0,2) }' > chr_list.txt

#(ADJUST HEADERS OF BAM FILES) - FIXED ORIGINAL CODE, NOT NEEDED
samtools view -H Sim4.sorted.dedup.bam | grep "@SQ" | less
samtools view -H Sim4.sorted.dedup.bam | grep -v "@SQ" | less

#FREEBAYES
FB=/programs/freebayes-v1.3.1/freebayes
REFFASTA=Sol_ref.fa
REGION=TRINITY_DN100_c0_g1_i11
$FB -f $REFFASTA \
Sim4.sorted.dedup.bam \
Sim5.sorted.dedup.bam \
Sim6.sorted.dedup.bam \
Sol6.sorted.dedup.bam \
Sol7.sorted.dedup.bam \
Sol8.sorted.dedup.bam \
Sol10.sorted.dedup.bam \
--min-mapping-quality 30 \
-r $REGION > fb_$REGION.vcf >& fb_$REGION.log &
#JOB LIST OVER ALL CONTIGS IN chr_list.txt

#COMBINE
#Header
grep "#" fb_TRINITY_DN100_c0_g1_i11.log | cat >> output.vcf 
#Then everybody else
grep -v "#" fb_TRINITY_DN1001*.log | cat >> output.vcf
#First do ten of them
#Don't forget the \ around internal quotes
for i in {0..9}
do
echo "echo $i"
echo "touch fb_vcf/output_DN$i.vcf"
echo "grep \"#\" fb_vcf/fb_TRINITY_DN0_c2_g1_i1.vcf | cat >> fb_vcf/output_DN$i.vcf"
echo "grep -v \"#\" fb_vcf/fb_TRINITY_DN$i*.vcf | cat >> fb_vcf/output_DN$i.vcf"
done > j_combine_fb_vcf.txt
#Checked to make sure they had all finished by doing tail -300+ to make sure there were 9s
#All in one
touch output_all.vcf
grep \"#\" output_DN1.vcf | cat >> output_all.vcf
grep -v \"#\" output_DN*.vcf | cat >> output_all.vcf
#FIX TEN TEN HEADER LINES
cat -n output_DN_all.vcf | sort -uk2 | sort -n | cut -f2- > output_DN_lesshead.vcf

#FILTER BY...
#1/1 AND 0/0 NO 0/1
#This filtering also removes instances of missing data
#Sorted for both
#grep "#" output_DN_lesshead.vcf > output_filter_1100.vcf
#Filtered one at a time to track which matches ref
grep "#" output_DN_lesshead.vcf > o_filter_Sim1_Sol0.vcf
grep "#" output_DN_lesshead.vcf > o_filter_Sim0_Sol1.vcf
#include BEGIN to print as \t delimited
awk 'BEGIN{FS=OFS="\t"}{if(\
$10 ~ "0/0" &&\
$12 ~ "0/0" &&\
$15 ~ "0/0" &&\
$16 ~ "0/0" &&\
$11 ~ "1/1" &&\
$13 ~ "1/1" &&\
$14 ~ "1/1"\
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' output_DN_all.vcf >> o_filter_Sim1_Sol0.vcf &
awk 'BEGIN{FS=OFS="\t"}{if(\
$10 ~ "1/1" &&\
$12 ~ "1/1" &&\
$15 ~ "1/1" &&\
$16 ~ "1/1" &&\
$11 ~ "0/0" &&\
$13 ~ "0/0" &&\
$14 ~ "0/0"\
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' output_DN_all.vcf >>  o_filter_Sim0_Sol1.vcf &

#QUALITY, DEPTH AND DISTANCE FROM INDELS
bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_filter_Sim1_Sol0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' > output_total_filter.vcf
bgzip < output_total_filter.vcf > o_total_filter.vcf.gz &
tabix o_total_filter.vcf.gz

#Primer3 and Prepare for SNPS2CAPS
CONTIGS=(
TRINITY_DN6365_c3_g1_i3 ... #Fill with all contigs to test
)

#Run this for loop in screen
for chr in ${CONTIGS[@]}
do 
echo "$chr"
samtools faidx Sol_ref.fa $chr > ref_chrs/ref_$chr.fa
tmpseq=$(samtools faidx Sol_ref.fa $chr | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
echo \
"SEQUENCE_ID=$chr
SEQUENCE_TEMPLATE=$tmpseq
PRIMER_TASK=generic
PRIMER_PICK_LEFT_PRIMER=1
PRIMER_PICK_INTERNAL_OLIGO=0
PRIMER_PICK_RIGHT_PRIMER=1
PRIMER_OPT_SIZE=20
PRIMER_MIN_SIZE=18
PRIMER_MAX_SIZE=22
PRIMER_PRODUCT_SIZE_RANGE=200-300
PRIMER_EXPLAIN_FLAG=1
PRIMER_NUM_RETURN=10
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1
=" > primer_attempts/primer_$chr.input
./primer3/src/primer3_core primer_attempts/primer_$chr.input > primer_attempts/primer_$chr.output
for NUM in 0 1 2 3 4 5 6 7 8 9
do
pleft=$(grep "PRIMER_LEFT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
pright=$(grep "PRIMER_RIGHT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')
bcftools view o_total_filter.vcf.gz -r $chr:$pleft-$pright -o primer_attempts/f_$chr.$NUM.vcf
usable=$(grep -v "#" primer_attempts/f_$chr.$NUM.vcf | wc -l)
if [ $usable -ge 1 ]; then
echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
echo "found $usable SNPS"
#SAVE THE FASTA FILE OF THAT PRIMER PRODUCT
samtools faidx Sol_ref.fa $chr:$pleft-$pright -o products/p_sol_$chr.$NUM.fasta
#Grab the fasta of any one similis from because they should all have the same snp at these sites (but what about added snps that it might pick up on)
#So maybe instead I could use the reference with the vcf (keep only the similis in the vcf)
bgzip -c primer_attempts/f_$chr.$NUM.vcf > primer_attempts/f_$chr.$NUM.vcf.gz
tabix primer_attempts/f_$chr.$NUM.vcf.gz
bcftools view primer_attempts/f_$chr.$NUM.vcf.gz -s Sim4 -O z > primer_attempts/f_sim_$chr.$NUM.vcf.gz
tabix primer_attempts/f_sim_$chr.$NUM.vcf.gz
samtools faidx ref_chrs/ref_$chr.fa $chr:$pleft-$pright  | vcf-consensus primer_attempts/f_sim_$chr.$NUM.vcf.gz > products/sim_$chr.$NUM.fasta
#Add species name to header
sed -i 's/>/>Sim_/' products/sim_$chr.$NUM.fasta
sed -i 's/>/>Sol_/' products/p_sol_$chr.$NUM.fasta
#Make into single file for SNP2CAPS
cat products/*_$chr.$NUM.fasta >> CAPS_input/input_SNP2CAP_$chr.$NUM.fasta
fi
done
done

#Take CAPS_input files to SNP2CAPS.exe on windows machine


#After finding the good ones, pull the data on the primers
while read candidate; do
echo $candidate
primernum=$(echo "$candidate" | grep -Eo '[0-9]+$') 
primercandidate=$(echo "${candidate%?}" | tr -d '[:space:]')
echo $primercandidate
grep "PRIMER_.*_$primernum" primer_attempts/primer_TRINITY_$primercandidate.output 
done < CANDIDATES.txt  > feb_23_primers_out.txt
#Where CANDIDATES.txt is a two column list of $isoform	$primer number - this is the input










########################################### NOTES ####################################
#Date: Feb 22 2021
#Sort by size
#NOPE: [Test from 850 to 1167]
# Getting new weird line: Looks as fasta file snippet, the sequence TRINITY_DN10732_c0_g1_i7 starts at position 2793
#  Right before the "found ____ SNPS line"
#       And then it is also reporting mulitple times for the same sequence with different numbers of SNPs <- that's fine it should print it for each primer pair it tries that works.
#   But then it looks like I have a chunk of stuff from the 4000s area.
#	Where are my primers from?
#    September: 0-600   October: 700-1800
# Instead Pull 2000-3000 and 5000-6000
#First put other ones in the bin. Done.
#Date: Feb 23 2021
# Remember to move all other ones to a folder that have been checked FIRST
# 6000-8250

# Candidates to pull primers


#Date: August 9 2020
#PRIMER3 and CALLING RFLP
#It sounds like I may need to identify the primer areas first and then check for rflp

#Required to install
git clone https://github.com/primer3-org/primer3.git primer3
cd primer3/src
make
make test
#Takes about 20 minutes

#Now, do I need to blast my transcriptome?
#Try blasting with PrimerBlast with default settings except minimum bp is 200
#PrimerBLAST doesn't like looking at files with multiple contigs

#Pull the biggest ones
grep ">T" Sol_ref.fa | less -S
#Used excel to find the longest ones
#Check fa at that contig and then vcf
samtools faidx Sol_ref.fa TRINITY_DN1893_c0_g1_i3
vcftools --vcf output_total_filter.vcf --chr TRINITY_DN1893_c0_g1_i3 --out filter_TRINITY_DN1893_c0_g1_i3.vcf

bgzip < output_total_filter.vcf > o_total_filter.vcf.gz &
tabix o_total_filter.vcf.gz
bcftools view o_total_filter.vcf.gz -r TRINITY_DN1893_c0_g1_i3 -o filter_TRINITY_DN1893_c0_g1_i3.vcf

grep -v "#" filter_TRINITY_DN1893_c0_g1_i3.vcf | less
#variable=$(complex_command)

tmp=$(samtools faidx Sol_ref.fa TRINITY_DN1893_c0_g1_i3 | grep -v ">" |tr -d "\n")

#samtools faidx reference.fasta lyrata:1-108


#Primer3 Set-up
#tmpseq=ACCTGTGTGACACACACAAAAATTGTGGGAATTTGGAGATTTAAGGTCCTCTAAGTTCTGAGCTCTTTCGGGAAACCCTTTTGTTTGGCACCACACACACACACAGTGTCAGCGCTATACGTGCATGTGACCTGTGTTCACAGTGTGTACACGTGTGTCACACTGTTTTTTGGGGAAACCCTGTGTACAACACAACACCCACACTGCGCGGCGGCGGTATAAAATTTGCCGCGTTGTGACACACACGTGTGTGTGTCACACAATATAATATCTCTCCGAGAGAGACTCTCTCGGGGGAAAACACCCTTTTGGGTTTTACACAACCCCACACACACTTTTTTGGGGGAAAAACCCCTGTTTGTTTACCCCAAAACCCAAACTTTTGGGTTCTCTCTACACATGGGTTTAACCCAAACCAACACAAACTTTGGGTTTACCCAAACCAAATTTGGGGTTCTCTACACAAACCCTTTTGGGGGGTTTGTACACTTGTGGTACAAATTGGCCAATGTGTACACAAATTGGTTCTCTGAATGTGTGTACTGGATGTGACACATGTGTGATATCGCTGTACGTACATGGTACCATGGTACCATGTGTAAATTGTGTGACACAAAAATTGTGACATGTATACGTCTGTGCAA
#tmpseq2=$(echo $tmpseq | tr '[A-Z]' '[a-z]')
#Well now, if I'm only getting ones 200-300 long, I don't need it from the biggest contigs do I?


chr=TRINITY_DN1893_c0_g1_i3
tmpseq=$(samtools faidx Sol_ref.fa $chr | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
echo \
"SEQUENCE_ID=$chr
SEQUENCE_TEMPLATE=$tmpseq
PRIMER_TASK=generic
PRIMER_PICK_LEFT_PRIMER=1
PRIMER_PICK_INTERNAL_OLIGO=0
PRIMER_PICK_RIGHT_PRIMER=1
PRIMER_OPT_SIZE=20
PRIMER_MIN_SIZE=18
PRIMER_MAX_SIZE=22
PRIMER_PRODUCT_SIZE_RANGE=200-300
PRIMER_EXPLAIN_FLAG=1
PRIMER_NUM_RETURN=30
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1
=" > primer_$chr.input
./primer3/src/primer3_core primer_$chr.input > primer3_$chr.output

PRIMER_LEFT_0=19634,20
PRIMER_RIGHT_0=19841,20

for NUM in 0 1 2 3 4 5 6 7 8 9
do
	pleft=$(grep "PRIMER_LEFT_$NUM=" primer2_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
	pright=$(grep "PRIMER_RIGHT_$NUM=" primer2_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')
	bcftools view o_total_filter.vcf.gz -r TRINITY_DN1893_c0_g1_i3:$pleft-$pright -o filter_TRINITY_DN1893_c0_g1_i3.vcf
	usable=$(grep -v "#" filter_TRINITY_DN1893_c0_g1_i3.vcf | wc -l)
	if [ $usable -ge 1 ]; then
		echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
	fi
done

#Where I will create a table:
echo -e "#CONTIG_TRINITY_ID\tPRIMER3PAIR\tLEFTSTART\tRIGHTSTART\tN_SNPS" > list_of_sites.txt



#For loop for the top 20 longest contigs
CONTIGS=(
TRINITY_DN1893_c0_g1_i3
TRINITY_DN3859_c0_g1_i4
TRINITY_DN5165_c1_g1_i9
TRINITY_DN1004_c0_g1_i5
TRINITY_DN698_c0_g1_i17
TRINITY_DN893_c0_g1_i16
TRINITY_DN2875_c0_g1_i5
TRINITY_DN1160_c0_g1_i4
TRINITY_DN2545_c0_g1_i1
TRINITY_DN1095_c0_g1_i12
TRINITY_DN482_c1_g1_i1
TRINITY_DN2744_c0_g1_i4
TRINITY_DN1699_c0_g1_i5
TRINITY_DN370_c0_g1_i6
TRINITY_DN297_c4_g1_i3
TRINITY_DN347_c0_g1_i6
TRINITY_DN754_c0_g3_i1
TRINITY_DN4627_c0_g1_i4
TRINITY_DN579_c0_g1_i5
TRINITY_DN1267_c0_g2_i10
)

mkdir primer_attempts
mkdir products
mkdir CAPS_input


# for chr in ${CONTIGS[@]}
# do 
# echo "$chr"
# samtools faidx Sol_ref.fa $chr > ref_$chr.fa
# tmpseq=$(samtools faidx Sol_ref.fa $chr | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
# echo \
# "SEQUENCE_ID=$chr
# SEQUENCE_TEMPLATE=$tmpseq
# PRIMER_TASK=generic
# PRIMER_PICK_LEFT_PRIMER=1
# PRIMER_PICK_INTERNAL_OLIGO=0
# PRIMER_PICK_RIGHT_PRIMER=1
# PRIMER_OPT_SIZE=20
# PRIMER_MIN_SIZE=18
# PRIMER_MAX_SIZE=22
# PRIMER_PRODUCT_SIZE_RANGE=200-300
# PRIMER_EXPLAIN_FLAG=1
# PRIMER_NUM_RETURN=10
# PRIMER_MIN_GC=45
# PRIMER_MAX_GC=60
# PRIMER_MAX_TM=62
# PRIMER_MAX_SELF_ANY=0.0
# PRIMER_MAX_SELF_END=0.0
# PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
# PRIMER_MAX_HAIRPIN_TH=30.0
# PRIMER_WT_HAIRPIN_TH=1
# =" > primer_attempts/primer_$chr.input
# ./primer3/src/primer3_core primer_attempts/primer_$chr.input > primer_attempts/primer_$chr.output
# for NUM in 0 1 2 3 4 5 6 7 8 9
# do
# 	pleft=$(grep "PRIMER_LEFT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
# 	pright=$(grep "PRIMER_RIGHT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')
# 	bcftools view o_total_filter.vcf.gz -r $chr:$pleft-$pright -o primer_attempts/f_$chr.$NUM.vcf
# 	usable=$(grep -v "#" primer_attempts/f_$chr.$NUM.vcf | wc -l)
# 	if [ $usable -ge 1 ]; then
# 		echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
# 		echo "found $usable SNPS"
# 		#SAVE THE FASTA FILE OF THAT PRIMER PRODUCT
# 		samtools faidx Sol_ref.fa $chr:$pleft-$pright -o products/p_sol_$chr.$NUM.fasta
# 		#Grab the fasta of any one similis from because they should all have the same snp at these sites (but what about added snps that it might pick up on)
# 		#So maybe instead I could use the reference with the vcf (keep only the similis in the vcf)
# 		bgzip -c primer_attempts/f_$chr.$NUM.vcf > primer_attempts/f_$chr.$NUM.vcf.gz
# 		tabix primer_attempts/f_$chr.$NUM.vcf.gz
# 		#Added to below line -r so it is also only the product produced for sim
# 		bcftools view primer_attempts/f_$chr.$NUM.vcf.gz -r $chr:$pleft-$pright -s Sim4 -O z > primer_attempts/f_sim_$chr.$NUM.vcf.gz
# 		tabix primer_attempts/f_sim_$chr.$NUM.vcf.gz
# 		cat ref_$chr.fa | vcf-consensus primer_attempts/f_sim_$chr.$NUM.vcf.gz > products/sim_$chr.$NUM.fasta
# 	fi
# done
# done

mkdir primer_attempts
mkdir products
mkdir CAPS_input

#COPY AND PASTED TO REMOVE TABS
for chr in ${CONTIGS[@]}
do 
echo "$chr"
samtools faidx Sol_ref.fa $chr > ref_$chr.fa
tmpseq=$(samtools faidx Sol_ref.fa $chr | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
echo \
"SEQUENCE_ID=$chr
SEQUENCE_TEMPLATE=$tmpseq
PRIMER_TASK=generic
PRIMER_PICK_LEFT_PRIMER=1
PRIMER_PICK_INTERNAL_OLIGO=0
PRIMER_PICK_RIGHT_PRIMER=1
PRIMER_OPT_SIZE=20
PRIMER_MIN_SIZE=18
PRIMER_MAX_SIZE=22
PRIMER_PRODUCT_SIZE_RANGE=200-300
PRIMER_EXPLAIN_FLAG=1
PRIMER_NUM_RETURN=10
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1
=" > primer_attempts/primer_$chr.input
./primer3/src/primer3_core primer_attempts/primer_$chr.input > primer_attempts/primer_$chr.output
for NUM in 0 1 2 3 4 5 6 7 8 9
do
pleft=$(grep "PRIMER_LEFT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
pright=$(grep "PRIMER_RIGHT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')
bcftools view o_total_filter.vcf.gz -r $chr:$pleft-$pright -o primer_attempts/f_$chr.$NUM.vcf
usable=$(grep -v "#" primer_attempts/f_$chr.$NUM.vcf | wc -l)
if [ $usable -ge 1 ]; then
echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
echo "found $usable SNPS"
#SAVE THE FASTA FILE OF THAT PRIMER PRODUCT
samtools faidx Sol_ref.fa $chr:$pleft-$pright -o products/p_sol_$chr.$NUM.fasta
#Grab the fasta of any one similis from because they should all have the same snp at these sites (but what about added snps that it might pick up on)
#So maybe instead I could use the reference with the vcf (keep only the similis in the vcf)
bgzip -c primer_attempts/f_$chr.$NUM.vcf > primer_attempts/f_$chr.$NUM.vcf.gz
tabix primer_attempts/f_$chr.$NUM.vcf.gz
bcftools view primer_attempts/f_$chr.$NUM.vcf.gz -s Sim4 -O z > primer_attempts/f_sim_$chr.$NUM.vcf.gz
tabix primer_attempts/f_sim_$chr.$NUM.vcf.gz
samtools faidx ref_$chr.fa $chr:$pleft-$pright  | vcf-consensus primer_attempts/f_sim_$chr.$NUM.vcf.gz > products/sim_$chr.$NUM.fasta
#Add species name to header
sed -i 's/>/>Sim_/' products/sim_$chr.$NUM.fasta
sed -i 's/>/>Sol_/' products/p_sol_$chr.$NUM.fasta
#Make into single file for SNP2CAPS
cat products/*_$chr.$NUM.fasta >> CAPS_input/input_SNP2CAP_$chr.$NUM.fasta
fi
done
done

#Date: August 19 2020
#Works!!

#Try running mine with SNP to CAPS
ls CAPS_input/ > inputs_CAPS_example.txt
#TR DOES NOT - Try sed?
tr -d ".fasta" inputs_CAPS_example.txt
tr -d "input_SNP2CAP_" inputs_CAPS_example.txt
mkdir CAPS_output

perl SNP2CAPS.pl example_SNPS2CAPS.fasta rebase.gcg out_SNPS2CAPS



#Date: August 24 2020
#Installing perl

#SKIPPED PART 1 - MOVE TO PART 2
which python3 
ls -l /usr/local/bin/python3
python3 -V
which pip3
head -n1 /usr/local/bin/pip3
#1.2 Install and use python module deepTools Install deepTools in the directory ~/.local/
pip3 install deepTools --user
export PATH=$HOME/.local/bin:$PATH
which deeptools
export LC_ALL=en_US.utf-8
export LANG=en_US.utf-8
deeptools
python3
import deeptools
deeptools.__file__
import numpy
numpy.__file__
numpy.__version__ 
pip3 install deepTools==3.3.2 --prefix /workdir/$USER --ignore-installed
export PATH=/workdir/$USER/bin:$PATH
export PYTHONPATH=/workdir/$USER/lib/python3.6/site-packages
which deeptools
export LC_ALL=en_US.utf-8
export LANG=en_US.utf-8
deeptools

#Part 2. Install PERL software with CPAN
mkdir ~/perl
export PERL5LIB=~/perl/lib/perl5
cpan
#I got different prompts - answered whatever was most automatic or default
#The below prompts show up eventually
#At cpan pompt “cpan[1]>”, type the following commands:
o conf makepl_arg INSTALL_BASE=~/perl 
o conf mbuild_arg INSTALL_BASE=~/perl 
#Please use 'o conf commit' to make the config permanent!
o conf prefs_dir ~/perl /prefs 
o conf commit
install XML::Simple

#This module is only accessible if you “export PERL5LIB=~/perl/lib/perl5”. Delete the whole directory /perl if installation goes wrong.
export PERL5LIB=~/perl/lib/perl5

#Installation
#BioPerl distribution has the same name as the BioPerl. However, the BioPerl distribution only includes a subset of the project modules. Because of this, the meaning of "installing BioPerl" is rarely clear. Instead of "install BioPerl", the aim must be "install module X".
CPAN.org provides an overview on how to install and manage Perl modules but the bottom-line is:

#find the module you need, for example Bio::DB::EUtilities
#install it with cpanm, for example cpanm Bio::DB::EUtilities
#Alternatively, some Linux distributions have packaged BioPerl and have it available through their package manager.

#it said restart shell before starting cpan again.
export PERL5LIB=~/perl/lib/perl5
cpan #(bioperl says cpanm but that doesn't look like a command)
install Bio::DB::EUtilities
#Took a while

#However Tk is installed here: export PERL5LIB=/programs/PERL/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi
install Tk::TK_PATCHLEVEL
#Says to try using perlbrew so lets see if I need it first
#Yep, need it

#Try just copying files from the place they were installed
cp -r /programs/PERL/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/*Tk* /home/hh693/perl/lib/perl5/x86_64-linux-thread-multi
#Can't tell for sure that Bioperl was installed

#Encode is missing
cp -r /programs/PERL/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/* /home/hh693/perl/lib/perl5/x86_64-linux-thread-multi
#This results in lots of permission denieds for things like encoding.

#Seemed more like it worked because it still popped up with "fasta" but still did not finish in 2 seconds

#Try with VNC GUI again
perl SNP2CAPS.pl -gui
#Says Tk module is still missing
#Maybe I need to initialize the perl area again
#Yep. New error:

bad option "padx": must be -after, -anchor, -before, -expand, -fill, -in, -ipadx, -ipady, -padx, -pady, or -side at /home/hh693/perl/lib/perl5/x86_64-linux-thread-multi/Tk/Widget.pm line 1217.
 at SNP2CAPS.pl line 122.




#Date: August 25 2020
#Expand to more contigs
CONTIGS=(
TRINITY_DN9354_c1_g1_i8
TRINITY_DN1450_c0_g1_i1
TRINITY_DN1584_c0_g2_i16
TRINITY_DN3363_c0_g1_i4
TRINITY_DN2796_c1_g1_i7
TRINITY_DN15869_c1_g1_i1
TRINITY_DN981_c0_g1_i5
TRINITY_DN2054_c0_g1_i4
)

#Repeat with following 300
mv ref_TRIN* primer_attempts/


for chr in ${CONTIGS[@]}
do 
echo "$chr"
samtools faidx Sol_ref.fa $chr > ref_chrs/ref_$chr.fa
tmpseq=$(samtools faidx Sol_ref.fa $chr | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
echo \
"SEQUENCE_ID=$chr
SEQUENCE_TEMPLATE=$tmpseq
PRIMER_TASK=generic
PRIMER_PICK_LEFT_PRIMER=1
PRIMER_PICK_INTERNAL_OLIGO=0
PRIMER_PICK_RIGHT_PRIMER=1
PRIMER_OPT_SIZE=20
PRIMER_MIN_SIZE=18
PRIMER_MAX_SIZE=22
PRIMER_PRODUCT_SIZE_RANGE=200-300
PRIMER_EXPLAIN_FLAG=1
PRIMER_NUM_RETURN=10
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1
=" > primer_attempts/primer_$chr.input
./primer3/src/primer3_core primer_attempts/primer_$chr.input > primer_attempts/primer_$chr.output
for NUM in 0 1 2 3 4 5 6 7 8 9
do
pleft=$(grep "PRIMER_LEFT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
pright=$(grep "PRIMER_RIGHT_$NUM=" primer_attempts/primer_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')
bcftools view o_total_filter.vcf.gz -r $chr:$pleft-$pright -o primer_attempts/f_$chr.$NUM.vcf
usable=$(grep -v "#" primer_attempts/f_$chr.$NUM.vcf | wc -l)
if [ $usable -ge 1 ]; then
echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
echo "found $usable SNPS"
#SAVE THE FASTA FILE OF THAT PRIMER PRODUCT
samtools faidx Sol_ref.fa $chr:$pleft-$pright -o products/p_sol_$chr.$NUM.fasta
#Grab the fasta of any one similis from because they should all have the same snp at these sites (but what about added snps that it might pick up on)
#So maybe instead I could use the reference with the vcf (keep only the similis in the vcf)
bgzip -c primer_attempts/f_$chr.$NUM.vcf > primer_attempts/f_$chr.$NUM.vcf.gz
tabix primer_attempts/f_$chr.$NUM.vcf.gz
bcftools view primer_attempts/f_$chr.$NUM.vcf.gz -s Sim4 -O z > primer_attempts/f_sim_$chr.$NUM.vcf.gz
tabix primer_attempts/f_sim_$chr.$NUM.vcf.gz
samtools faidx ref_chrs/ref_$chr.fa $chr:$pleft-$pright  | vcf-consensus primer_attempts/f_sim_$chr.$NUM.vcf.gz > products/sim_$chr.$NUM.fasta
#Add species name to header
sed -i 's/>/>Sim_/' products/sim_$chr.$NUM.fasta
sed -i 's/>/>Sol_/' products/p_sol_$chr.$NUM.fasta
#Make into single file for SNP2CAPS
cat products/*_$chr.$NUM.fasta >> CAPS_input/input_SNP2CAP_$chr.$NUM.fasta
fi
done
done

#Sorted by size, start again at 1168



#Test on new server:
#Date: October 2 2020
mkdir /workdir/hh693
cd /workdir/hh693
mkdir CAPS_input .
mkdir primer_attempts . 
mkdir products .
cp /home/mph75_0001/shared/Hannah/MarkerDevelopment/Sol_ref* .
cp -r /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/SNP2CAPS/primer3 . 
#Can't find o_total_filter.vcf.gz
#Pull the biggest ones
#grep ">T" Sol_ref.fa | less -S
#Used excel to find the longest ones
#Check fa at that contig and then vcf
#RETAB FILTER SIM 1 and SOL 0 FOR o_tab_S1S0.vcf
#FIX THE VCFTOOLS NOT LIKING THE HEASDER
#Quick workaround: index the file with tabix
#first compress - ERROR: Failed to parse TBX_VCF, was wrong -p [type] used?
#CAUSE THESE ONES ARE STILL NOT TAB-DELIMETERED
#o_filter_Sim1_Sol0.vcf
	#grep "#" o_filter_Sim1_Sol0.vcf > o_tab_S1S0.vcf
	#grep -v "#" o_filter_Sim1_Sol0.vcf | tr " " "\t" >> o_tab_S1S0.vcf #Not working - looks like I might have fixed o_filter_Sim0_Sol1.vcf cause it looks tabbed
	#bgzip -c o_tab_S1S0.vcf > o_tab_S1S0.vcf.gz
	#bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' > output_total_filter.vcf
	#bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_filter_Sim1_Sol0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' > output_total_filter.vcf
	#samtools faidx Sol_ref.fa TRINITY_DN1893_c0_g1_i3
	#vcftools --vcf output_total_filter.vcf --chr TRINITY_DN1893_c0_g1_i3 --out filter_TRINITY_DN1893_c0_g1_i3.vcf
	#bgzip < output_total_filter.vcf > o_total_filter.vcf.gz &
	#tabix o_total_filter.vcf.gz
	#bcftools view o_total_filter.vcf.gz -r TRINITY_DN1893_c0_g1_i3 -o filter_TRINITY_DN1893_c0_g1_i3.vcf
#o_total_filter.vcf.gz
# cp /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/SNP2CAPS/SNP2CAPS.pl

cp ???/o_total_filter.vcf.gz
tabix o_total_filter.vcf.gz


#CONTIGS
CONTIGS=(
TRINITY_DN9354_c1_g1_i8
TRINITY_DN1450_c0_g1_i1
TRINITY_DN1584_c0_g2_i16
TRINITY_DN3363_c0_g1_i4
TRINITY_DN2796_c1_g1_i7
TRINITY_DN15869_c1_g1_i1
TRINITY_DN981_c0_g1_i5
TRINITY_DN2054_c0_g1_i4
)

#Compare to original thingies saved from last time for these contigs
#These weren't save so repeat with some of the ones I do have saved:

CONTIGS=(
TRINITY_DN6365_c3_g1_i3
TRINITY_DN6094_c1_g1_i5
TRINITY_DN600_c0_g1_i4
TRINITY_DN5814_c0_g1_i1
TRINITY_DN5710_c0_g1_i2
TRINITY_DN6432_c0_g1_i1
)

cmp CAPS_input/input_SNP2CAP_TRINITY_DN6365_c3_g1_i3.4.fasta /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/SNP2CAPS/CAPS_input/input_SNP2CAP_TRINITY_DN6365_c3_g1_i3.4.fasta
cmp CAPS_input/input_SNP2CAP_TRINITY_DN6432_c0_g1_i1.4.fasta /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/SNP2CAPS/CAPS_input/input_SNP2CAP_TRINITY_DN6432_c0_g1_i1.4.fasta
#For files that are identical, 'cmp' produces no output.
#Looking good

#Notice that a list_of_sites.txt file was produced with multiple collumn, unsure where it comes from
#echo -e "$chr\t$NUM\t$pleft\t$pright\t$usable" >> list_of_sites.txt
#CHR	#PRIMER PAIR NUMBER		#pos_LEFT		#pos_RIGHT		#Is it usable?(aka number of internal SNPS > 0)


#Copy all files via file zilla then on my own terminal, use the list of filtered viable (and not tested) on my computer to move to new directory
repeaters=(

)

#cd Documents/Hare_Lab/Spisula/SNP2CAPS_inputs/
#OR DO IT INSIDE SERVER
ls | wc -l
for r in ${repeaters[@]}
do 
mv CAPS_input/$r CAPS_input/checked/$r
done
#removes about 700 of them
#Worked through 1-2000 longest contigs

#ALSO: FOR TODAY - MOVE ALL BEFORE 1116 TO POSSIBLY CHECKED
possibles=()
for ppp in ${possibles[@]}
do 
mv CAPS_input/*$ppp* CAPS_input/possibles/$ppp
done
#Only moved 12? Could it be the only 12 since the last time I moved the known duplicates? No


#Once I SNP check, pull primer stats
candidate=TRINITY_DN999_c3_g1_i8

rm CANDIDATES.txt 
touch CANDIDATES.txt 
nano CANDIDATES.txt 
#copy and paste
TRINITY_DN10732_c0_g1_i7 1
TRINITY_DN1723_c0_g2_i1 0
TRINITY_DN1723_c0_g2_i1 1
TRINITY_DN1751_c0_g1_i4 0

#WORKS! PULLS PRIMER STATS FOR ONLY THE RELEVANT PRIMER PAIR from above 2 collumn data
while read candidate; do
echo $candidate
primernum=$(echo "$candidate" | grep -Eo '[0-9]+$') 
primercandidate=$(echo "${candidate%?}" | tr -d '[:space:]')
#echo $primercandidate
grep "PRIMER_.*_$primernum" primer_attempts/primer_$primercandidate.output 
done < CANDIDATES.txt > Oct21_primer_out.txt

sed 's/=/\t/g' Oct2_eve_primer_out.txt > primer_tabbed2.txt



#Date: October 3rd 2020
#New method: align by longer contigs now that I'm only looking for 4 enzymes

#650 to 700 by size
for chr in ${CONTIGSTEST[@]}
do 
echo "$chr"
samtools faidx Sol_ref.fa $chr > ref_chrs/ref_$chr.fa
bcftools view o_total_filter.vcf.gz -r $chr -o contig_CAPS_input/f/f_$chr.vcf
#SAVE THE FASTA FILE OF THAT PRIMER PRODUCT
samtools faidx Sol_ref.fa $chr -o contig_CAPS_input/products/p_sol_$chr.fasta
#Grab the fasta of any one similis from because they should all have the same snp at these sites (but what about added snps that it might pick up on)
#So maybe instead I could use the reference with the vcf (keep only the similis in the vcf)
bgzip -c contig_CAPS_input/f/f_$chr.vcf > contig_CAPS_input/f/f_$chr.vcf.gz
tabix contig_CAPS_input/f/f_$chr.vcf.gz
bcftools view contig_CAPS_input/f/f_$chr.vcf.gz -s Sim4 -O z > contig_CAPS_input/f/f_sim_$chr.vcf.gz
tabix contig_CAPS_input/f/f_sim_$chr.vcf.gz
samtools faidx ref_chrs/ref_$chr.fa $chr  | vcf-consensus contig_CAPS_input/f/f_sim_$chr.vcf.gz > contig_CAPS_input/products/sim_$chr.fasta
#Add species name to header
sed -i "s/>/>Sim_/" contig_CAPS_input/products/sim_$chr.fasta
sed -i "s/>/>Sol_/" contig_CAPS_input/products/p_sol_$chr.fasta
#Make into single file for SNP2CAPS
cat contig_CAPS_input/products/*_$chr.fasta >> contig_CAPS_input/input_SNP2CAP_$chr.fasta
#sed -i "s/>T/>Sol_T" contig_CAPS_input/input_SNP2CAP_$chr.fasta
done

#Date: October 15
# use those contigs outputs to find primers and test more contigs 
#And test 700 to 850

#now find primers at those good positions
#for chr in ${CONTIGS[@]}
#do 

chr=TRINITY_DN1751_c0_g1_i4
pos=2521
pleft=$(($pos-150))
pright=$(($pos+200))

echo "$chr"
samtools faidx Sol_ref.fa  $chr:$pleft-$pright > ref_chrs/ref_$chr-$pleft-$pright.fa
tmpseq=$(samtools faidx Sol_ref.fa $chr:$pleft-$pright | grep -v ">" |tr -d "\n" | tr '[A-Z]' '[a-z]')
echo \
"SEQUENCE_ID=$chr
SEQUENCE_TEMPLATE=$tmpseq
PRIMER_TASK=generic
PRIMER_PICK_LEFT_PRIMER=1
PRIMER_PICK_INTERNAL_OLIGO=0
PRIMER_PICK_RIGHT_PRIMER=1
PRIMER_OPT_SIZE=20
PRIMER_MIN_SIZE=18
PRIMER_MAX_SIZE=22
PRIMER_PRODUCT_SIZE_RANGE=200-300
PRIMER_EXPLAIN_FLAG=1
PRIMER_NUM_RETURN=10
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1
=" > primer_attempts/primer_$chr-$pleft-$pright.input
./primer3/src/primer3_core primer_attempts/primer_$chr-$pleft-$pright.input > contig_CAPS_input/primers_out/primer_$chr-$pleft-$pright.output
returned=$(grep "PRIMER_PAIR_NUM_RETURNED=" contig_CAPS_input/primers_out/primer_$chr-$pleft-$pright.output | sed 's/^.\{25\}//')
#if [$returned -ne 0]; then
#less contig_CAPS_input/primers_out/primer_$chr-$pleft-$pright.output
#fi

less contig_CAPS_input/primers_out/primer_$chr-$pleft-$pright.output

#done




samtools faidx Sol_ref.fa  $chr:622-922 > ref_chrs/ref_$chr-622-922.fa








#Pull Primer info
primer_TRINITY_DN*.output



#Naming primers
#the accession 'TRINITY_DN1000_c115_g5_i1' indicates Trinity read cluster 'TRINITY_DN1000_c115', gene 'g5', and isoform 'i1'
#So I should not need to include i # because there should be no duplicates

#g up to 7, no double digits, no g0
#c0, up past c30 but not triple

#Numbers ######_### A   R
#         DN    c g *  L/R        * only included when more than one primer per contig
#         1-6   2-3 0-1 1 digits

#Spis######_###AR



#Added to below line -r so it is also only the product produced for sim
-r $chr:$pleft-$pright 
samtools faidx ref_$chr.fa $chr:$pleft-$pright  | vcf-consensus in.vcf.gz > out.fa
#THIS WORKS BUT MAKES THEIR HEADERS THE SAME
#Add line that changes header names
grep ">" 
#tr ">" ">Sol_" product/sim_TRINITY_DN1004_c0_g1_i5.2.fasta 
less products/sim_TRINITY_DN1004_c0_g1_i5.2.fasta 
sed -i 's/>/>Sim_/' products/sim_TRINITY_DN1004_c0_g1_i5.2.fasta 
sed -i 's/>/>Sol_/' products/p_sol_TRINITY_DN1004_c0_g1_i5.2.fasta 
less products/p_sol_TRINITY_DN1004_c0_g1_i5.2.fasta 


#Each contig takes about 10 seconds

#vcftools
#first you have to bgzip and tabix
bgzip -c primer_attempts/f_TRINITY_DN1004_c0_g1_i5.2.vcf > primer_attempts/f_TRINITY_DN1004_c0_g1_i5.2.vcf.gz
tabix primer_attempts/f_TRINITY_DN1004_c0_g1_i5.2.vcf.gz
bcftools view primer_attempts/f_TRINITY_DN1004_c0_g1_i5.2.vcf.gz -s Sim4 | grep -v "##" | less

chr=TRINITY_DN1004_c0_g1_i5
NUM=3
pleft=10086
pright=10341

samtools faidx products/sim_$chr.$NUM.fasta -r $chr:$pleft-$pright
samtools faidx products/sim_$chr.$NUM.fasta

samtools faidx sim_$chr.$NUM.fasta

samtools faidx Sol_ref.fa $chr > ref_$chr.fa


cat Sol_ref.fa | vcf-consensus primer_attempts/f_TRINITY_DN1004_c0_g1_i5.2.vcf.gz  > products/sim_TRINITY_DN1004_c0_g1_i5.2.fasta 


#Primer3
#SNP2CAPS Perl Script
modified FASTA formatted file that may contain data of more than one multiple alignment.
Structure of the header line:
">id_seqname" (with "id" = name of the multiple alignment and "seqname" = sequence name, see example)
#example
>GBS0734_Barke
TTCTTCCCAAGATACTTGGAGACCCTCGACTACTACACGGCAATGTTTGAGTCAATAGACGTTGCTCTCCCGAGGGATGATAAGAGGCGGATTAGCACGGAGCAGCACTGTGTTGCAAGGGATATTGTCAACTTAATCGCGTGTGAGGGTGCGGAAAGGGTGGAGAGGCATGAGGTGTTTGGGAAATGGAAGGCAAGGTTTGCAATGGCTGGATTTAGGCCGTACCCGCTGAGCTCAGTGGTGAACAACACCATCAAAACACTACTGAATAGCTACCACAGTTGCTACAGGCTTGAGGAGAGGGACGGGGTCCTTTTCC
>GBS0734_Dom
TTCTTCCCAAGATACTTGGAGACCCTCGACTACTACACGGCAATGTTTGAGTCAATAGACGTTGCTCTCCCGAGGGATGATAAGAGGCGGATTAGCACGGAGCAGCACTGTGTTGCAAGGGATATTGTCAACTTAATCGCGTGTGAGGGTGCGGAAAGGGTGGAGAGGCATGAGGTGTTTGGGAAATGGAAGGCAAGGTTTGCAATGGCTGGATTTAGGCCGTACCCGCTGAGCTCAGTGGTGAACAACACCATCAAAACACTACTGAATAGCTACCACAGTTGCTACAGGCTTGAGGAGAGGGACGGGGTCCTTTTCC
>GBS0734_Igri
TTCTTCCCAAGATACTTGGAGACCCTCGACTACTACACGGCAATGTTTGAGTCAATAGACGTTGCTCTCCCGAGGGATGATAAGAGGCGGATTAGCACGGAGCAGCACTGTGTTGCAAGGGATATCGTCAACTTAATTGCGTGCGAGGGTGCGGAAAGGGTAGAGAGGCATGAGGTGTTTGGGAAATGGAAGACAAGGTTTGCAATGGCTGGATTTAGGCCGTACCCGCTGAGTTCAGTGGTGAACAACACCATCAAAACACTGCTGAATAGCTACCACAGTTGCTACAGGCTTGAGGAGAGGGACGGAGTCCTTTTCC
>GBS0734_Franka
TTCTTCCCAAGATACTTGGAGACCCTCGACTACTACACGGCAATGTTTGAGTCAATAGACGTTGCTCTCCCGAGGGATGATAAGAGGCGGATTAGCACGGAGCAGCACTGTGTTGCAAGGGATATCGTCAACTTAATCGCGTGTGAGGGTGCGGAAAGGGTGGAGAGGCATGAGGTGTTTGGGAAATGGAAGGCAAGGTTTGCAATGGCTGGATTTAGGCCGTACCCGCTGAGCTCAGTGGTGAACAACACCATCAAAACACTACTGAATAGCTACCACAGTTGCTACAGGCTTGAGGAGAGGGACGGGGTCCTTTTCC
#Try with example
#Remember to make executable
chmod a+x SNP2CAPS.pl 

SNP2CAPS.pl example_SNPS2CAPS.fasta rebase.gcg
#Requires Tk.pm
#wget
wget https://www.cpan.org/modules/by-module/Tk/Tk-804.035.readme
#This may require BioHPC crew help

#Date: August 19 2020
#Run example
#Qi email perl
export PERL5LIB=/programs/PERL/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi
chmod a+x SNP2CAPS.pl 

perl SNP2CAPS.pl example_SNPS2CAPS.fasta rebase.gcg out_SNPS2CAPS
#Extra line with "fasta" popped up 
#Tried responding with "y" - no change
#But did run
#Started 11:51 - done at MORE THAN 15 minutes





#FROM
pleft=$(grep "PRIMER_LEFT_$NUM=" primer2_$chr.output | sed 's/^.\{14\}//' | sed 's/.\{3\}$//')
#TO
pright=$(grep "PRIMER_RIGHT_$NUM=" primer2_$chr.output | sed 's/^.\{15\}//' | sed 's/.\{3\}$//')

pleft=100
pright=5000
bcftools view o_total_filter.vcf.gz -r TRINITY_DN1893_c0_g1_i3:$pleft-$pright -o filter_TRINITY_DN1893_c0_g1_i3.vcf
grep -v "#" filter_TRINITY_DN1893_c0_g1_i3.vcf | wc -l
#If this wc value is non zero then there is a SNP in the primer region


#Took about 1.5 sec with the extra parameters, before it was instantaneous
PRIMER_NUM_RETURN=10
PRIMER_MIN_GC=45
PRIMER_MAX_GC=60
PRIMER_MAX_TM=62
PRIMER_MAX_SELF_ANY=0.0
PRIMER_MAX_SELF_END=0.0
PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1
PRIMER_MAX_HAIRPIN_TH=30.0
PRIMER_WT_HAIRPIN_TH=1


#Produces these
PRIMER_PAIR_9_PENALTY=0.071899
PRIMER_LEFT_9_PENALTY=0.037326
PRIMER_RIGHT_9_PENALTY=0.034574
PRIMER_LEFT_9_SEQUENCE=gcagtcaactggtcgatgga
PRIMER_RIGHT_9_SEQUENCE=tggtgggcgataatgttgct
PRIMER_LEFT_9=9042,20
PRIMER_RIGHT_9=9321,20
PRIMER_LEFT_9_TM=60.037
PRIMER_RIGHT_9_TM=60.035
PRIMER_LEFT_9_GC_PERCENT=55.000
PRIMER_RIGHT_9_GC_PERCENT=50.000
PRIMER_LEFT_9_SELF_ANY_TH=11.87
PRIMER_RIGHT_9_SELF_ANY_TH=0.00
PRIMER_LEFT_9_SELF_END_TH=0.00
PRIMER_RIGHT_9_SELF_END_TH=0.00
PRIMER_LEFT_9_HAIRPIN_TH=43.94
PRIMER_RIGHT_9_HAIRPIN_TH=37.39
PRIMER_LEFT_9_END_STABILITY=3.4100
PRIMER_RIGHT_9_END_STABILITY=3.9100
PRIMER_PAIR_9_COMPL_ANY_TH=2.64
PRIMER_PAIR_9_COMPL_END_TH=1.48
PRIMER_PAIR_9_PRODUCT_SIZE=280

#options
#  PRIMER_PRODUCT_SIZE_RANGE=100-300
  PRIMER_SECONDARY_STRUCTURE_ALIGNMENT=0 #Print them out, not needed, 
  PRIMER_NUM_RETURN=5
  PRIMER_MAX_HAIRPIN_TH=47.0
  PRIMER_INTERNAL_MAX_HAIRPIN_TH=47.0
  PRIMER_MAX_END_STABILITY=100.0
  PRIMER_MIN_LEFT_THREE_PRIME_DISTANCE=-1
  PRIMER_MIN_RIGHT_THREE_PRIME_DISTANCE=-1
  PRIMER_EXPLAIN_FLAG=0
  PRIMER_LIBERAL_BASE=0
  PRIMER_FIRST_BASE_INDEX=0
  PRIMER_MAX_TEMPLATE_MISPRIMING=-1.00
  PRIMER_MAX_TEMPLATE_MISPRIMING_TH=-1.00
  PRIMER_PAIR_MAX_TEMPLATE_MISPRIMING=-1.00
  PRIMER_PAIR_MAX_TEMPLATE_MISPRIMING_TH=-1.00 #Negative values mean dont check

PRIMER_OPT_GC_PERCENT (float; default 50.0)
Optimum GC percent. This parameter influences primer selection only if PRIMER_WT_GC_PERCENT_GT or PRIMER_WT_GC_PERCENT_LT are non-0.
#From lab of primer development: what where the best parameters
#17-28 in length : stick to defaults 18-22
#40-60 GC : change max from 80 to 60 or even less (very narrow range)
#TM between 52 and 62 : defaults are probably fine - DEFAULT OPT is 60, Min is 57, I set max to 62
#primer dimers and self-complementation and secondary structures : try to be as stringent as possible
		#could decrease 
		#PRIMER_MAX_SELF_ANY (decimal, 9999.99; default 8.00) where 0.0 is none but I don't understand if the negative values are acceptible
		#PRIMER_MAX_SELF_ANY_TH (decimal, 9999,99; default 47.00) does it by temp where unstable structure are still allowed cause they would melt so easily
		#PRIMER_PAIR_MAX_COMPL_ANY describes the tendency of the left primer to bind to the right primer. It is the maximum allowable local alignment score when testing for complementarity between left and right primers. It is similar to PRIMER_MAX_SELF_ANY.  (decimal, 9999.99; default 8.00)
		#PRIMER_WT_SELF_ANY (float; default 0.0) for _TH too
		#PRIMER_MAX_SELF_END (decimal, 9999.99; default 3.00) where a score of 0 means none
		#PRIMER_PAIR_MAX_COMPL_END tries to bind the 3'-END of the left primer to the right primer and scores the best binding it can find. It is similar to PRIMER_MAX_SELF_END.
		#PRIMER_WT_SELF_END (float; default 0.0) set to 1?
		#PRIMER_THERMODYNAMIC_OLIGO_ALIGNMENT=1 (CHECKS FOR HAIRPINS)
		#PRIMER_MAX_HAIRPIN_TH (float; default 47.0) by deafault should be 10 degrees less than 
		#PRIMER_WT_HAIRPIN_TH (float; default 0.0)
		#PRIMER_MAX_END_STABILITY (float, 999.9999; default 100.0) The maximum stability for the last five 3' bases of a left or right primer. Bigger numbers mean more stable 3' ends. 
		
		

#Use this same thing with internals to do the non RFLP one


#loop over
while read REGION; do
echo $REGION
done < chr_list.txt





SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
SAMPLES=(
    CUP_265
    CUP_352
    GA_007
    GA_008
    MCX_082
    PEC_011
    SHN_126
    TEST_010
)
for SAMPLE in "${SAMPLES[@]}"; do
	echo "$SAMPLE" > $SAMPLE.txt
done
vcftools --vcf fb_original.vcf --weir-fst-pop Sim4.txt --weir-fst-pop Sim5.txt --weir-fst-pop Sim6.txt --weir-fst-pop Sol6.txt --weir-fst-pop Sol8.txt --weir-fst-pop Sol7.txt --weir-fst-pop Sol10.txt --out dpq_ind_pilot
Weir and Cockerham mean Fst estimate: -nan
Weir and Cockerham weighted Fst estimate: -nan
#DOES NOT WORK ONE BY ONE

#Date: August 6 2020
#Rerunning the original and pilot data to confirm fst values
#Initialize
#Could redo by doing freebayes chromosome by chromosome for pilot data too

#FreeBayes
screen
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
FB=/programs/freebayes-v1.3.1/freebayes
$FB -f Sol_ref.fa CUP_265.sorted.dedup.bam CUP_352.sorted.dedup.bam MCX_082.sorted.dedup.bam PEC_011.sorted.dedup.bam GA_007.sorted.dedup.bam GA_008.sorted.dedup.bam SHN_126.sorted.dedup.bam TEST_010.sorted.dedup.bam --min-mapping-quality 30 > fb_pilot_2_GBS.vcf >& fb_2_GBS.log &

2934592	output_DN_lesshead.vcf 
2815705	grepped

383738	fb_pilot_GBS.vcf
264851	grepped



#Filling out table
bcftools filter --thread 8 --include 'COUNT(GT="mis")=0' fb_original.vcf > no_miss_original.vcf &
bcftools filter --thread 8 --include 'COUNT(GT="mis")=0' fb_pilot.vcf > no_miss_pilot.vcf &

# f2 Remove missing data, site depth >200 and <2001 and QUAL
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' no_miss_original.vcf | bcftools filter --include 'QUAL>100' > f2_original.vcf &
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' no_miss_pilot.vcf | bcftools filter --include 'QUAL>100' > f2_pilot.vcf &
vcftools --vcf f2_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out f2_pilot
Weir and Cockerham mean Fst estimate: 0.064626
Weir and Cockerham weighted Fst estimate: 0.06938
After filtering, kept 852 out of a possible 852 Sites
vcftools --vcf f2_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out f2_original
Weir and Cockerham mean Fst estimate: 0.23902
Weir and Cockerham weighted Fst estimate: 0.40385
After filtering, kept 649867 out of a possible 649867 Sites


#f3 Remove missing data, site depth >200 and <2001
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' no_miss_original.vcf > f3_original.vcf &
vcftools --vcf f3_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out f3_original
Weir and Cockerham mean Fst estimate: 0.20888
Weir and Cockerham weighted Fst estimate: 0.37865
After filtering, kept 856228 out of a possible 856228 Sites

#f4 Remove missing data, site depth >80 and <2001 (8 samples x 10 average depth)
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_original.vcf > f4_original.vcf &
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_pilot.vcf > f4_pilot.vcf &
vcftools --vcf f4_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out f4_original
Weir and Cockerham mean Fst estimate: 0.20263
Weir and Cockerham weighted Fst estimate: 0.36853
After filtering, kept 1440047 out of a possible 1440047 Sites

vcftools --vcf f4_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out f4_pilot
Weir and Cockerham mean Fst estimate: 0.041762
Weir and Cockerham weighted Fst estimate: 0.06444
After filtering, kept 29160 out of a possible 29160 Sites


#f5 Remove missing data, site depth >80 and <2001, QUAL>100
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_original.vcf | bcftools filter --include 'QUAL>100' > f5_original.vcf &
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_pilot.vcf | bcftools filter --include 'QUAL>100' > f5_pilot.vcf &

vcftools --vcf f5_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out f5_original
Weir and Cockerham mean Fst estimate: 0.24599
Weir and Cockerham weighted Fst estimate: 0.40495
After filtering, kept 1025231 out of a possible 1025231 Sites
vcftools --vcf f5_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out f5_pilot
Weir and Cockerham mean Fst estimate: 0.071536
Weir and Cockerham weighted Fst estimate: 0.07682
After filtering, kept 6751 out of a possible 6751 Sites


#f6 Remove missing data, site depth >80 and <2001, QUAL>10 (pilot data has much lower quality)
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_original.vcf | bcftools filter --include 'QUAL>10' > f6_original.vcf &
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_miss_pilot.vcf | bcftools filter --include 'QUAL>10' > f6_pilot.vcf &

vcftools --vcf f6_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out f6_original
Weir and Cockerham mean Fst estimate: 0.22849
Weir and Cockerham weighted Fst estimate: 0.39053
After filtering, kept 1137437 out of a possible 1137437 Sites
vcftools --vcf f6_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out f6_pilot
Weir and Cockerham mean Fst estimate: 0.066706
Weir and Cockerham weighted Fst estimate: 0.079817
After filtering, kept 11788 out of a possible 11788 Sites


#Filter
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' fb_original.vcf | bcftools filter --include 'QUAL>100' > dpq_original.vcf &
681303
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' fb_pilot.vcf | bcftools filter --include 'QUAL>100' > dpq_pilot.vcf &
853 	#<- welp thats no good

bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' no_miss_pilot.vcf > f2_pilot.vcf &
vcftools --vcf f2_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out f2_pilot
Weir and Cockerham mean Fst estimate: 0.040302
Weir and Cockerham weighted Fst estimate: 0.063555


#Try by individual 
bcftools filter --include 'MIN(FORMAT/DP)>10' fb_pilot.vcf > idp_pilot.vcf &
9755
#Remove missing by "mis" then by "."
bcftools filter --thread 8 --include 'COUNT(GT="mis")=0' fb_pilot.vcf > no_miss_pilot.vcf &
82891
bcftools filter --thread 8 --include 'COUNT(GT=".")=0' fb_pilot.vcf > no_missdot_pilot.vcf &
82891 #<- good suppose they should match
vcftools --vcf no_miss_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out no_f_pilot
Weir and Cockerham mean Fst estimate: 0.075007
Weir and Cockerham weighted Fst estimate: 0.1392


#Try estimating FST for really small files
vcftools --vcf dpq_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out dpq_pilot
Weir and Cockerham mean Fst estimate: 0.064626
Weir and Cockerham weighted Fst estimate: 0.06938
vcftools --vcf idp_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out idp_pilot
Weir and Cockerham mean Fst estimate: 0.037945
Weir and Cockerham weighted Fst estimate: 0.05949



#Try without filtering at all
vcftools --vcf fb_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out no_f_pilot
Weir and Cockerham mean Fst estimate: 0.075007
Weir and Cockerham weighted Fst estimate: 0.1392

vcftools --vcf fb_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out no_f_original
Weir and Cockerham mean Fst estimate: 0.20791
Weir and Cockerham weighted Fst estimate: 0.37488


#Just try to get general stats
bcftools stats --depth 1,2000,1 --samples-file pilotlist fb_pilot.vcf  > pilot.stats.vchk 2> pilot.stats.vchk.err
#It's the depth that's super low, basicallly it has no snps over depth 160, sites max out around 400, with most <200
#80 = 10*8 reads depth
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' fb_pilot.vcf > less_dpq_pilot.vcf &
6884 #<- still too little with QUAL>99
#Try without quality
29517
#Try with quality >10 - this might be removing sites without all non missing
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' fb_pilot.vcf | bcftools filter --include 'QUAL>10' > less_dp_minq_pilot.vcf &
11971
#And try with nonmissing and depth
bcftools filter --include 'INFO/DP>80 && INFO/DP<2000' no_missdot_pilot.vcf | bcftools filter --include 'QUAL>10' > no_miss_dpq_pilot.vcf &
29161 #(without quality)
11789 #(with quality) -> TRY FST OF THIS
vcftools --vcf no_miss_dpq_pilot.vcf --weir-fst-pop Sim_pilot --weir-fst-pop Sol_pilot --out min_f_pilot
Weir and Cockerham mean Fst estimate: 0.066706
Weir and Cockerham weighted Fst estimate: 0.079817
After filtering, kept 11788 out of a possible 11788 Sites
#Repeat with original
bcftools filter --thread 8 --include 'COUNT(GT="mis")=0' fb_original.vcf | bcftools filter --thread 8 --include 'INFO/DP>80 && INFO/DP<2000' | bcftools filter --include 'QUAL>10' > no_miss_dpq_original.vcf &
vcftools --vcf no_miss_dpq_original.vcf --weir-fst-pop Sim_original --weir-fst-pop Sol_original --out min_f_original
Weir and Cockerham mean Fst estimate: 0.22849
Weir and Cockerham weighted Fst estimate: 0.39053
After filtering, kept 1137437 out of a possible 1137437 Sites




#bcftools filter options
-S, --set-GTs .|0
#set genotypes of failed samples to missing value (.) or reference allele (0)
--threads INT
-i or -e 'expression'
GT="."
GT[@samples.txt]="het"
GT="mis"
COUNT(GT="hom")=0 #no homozygous genotypes at the site


bcftools filter --include 'MIN(FORMAT/DP)>10' fb_original.vcf  | grep -v "##" | wc -l
bcftools filter --include 'MIN(FORMAT/DP)>10' fb_pilot.vcf > idp_pilot.vcf &


bcftools stats --depth 1,2000,1 --samples-file samplelist.txt o_filter_Sim1_Sol0.vcf.gz  > o_filter_Sim1_Sol0.vcf.vchk 2> output_Sim1Sol0.stats.vchk.err

bcftools filter --include 'MIN(FORMAT/DP)>10' o_tab_S1S0.vcf | grep -v "##" | wc -l
27k <- individual
bcftools filter --include 'MIN(INFO/DP)>10' o_tab_S1S0.vcf | grep -v "##" | wc -l
85k <- group 
bcftools filter --include 'INFO/DP>200' o_tab_S1S0.vcf | grep -v "##" | wc -l
39253
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | grep -v "##" | wc -l
34028

bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'TYPE="snp"' | grep -v "##" | wc -l
bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' | grep -v "##" | wc -l
27580
#NOTE PUTTING A CAP ON THE QUALITY REMOVES A LOT


#CHART
#TOTAL
2,815,704
#NO MISSING AND NO PHASED
307,735
#DIANOGSTIC
85,954
#DEPTH (200-1500)
34,028
#DISTANCE FROM INDELS 
33,468
#SNPs only
27,830


awk '{if($6 > 100 && ) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' o_filter_Sim1_Sol0.vcf | wc -l


bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' > output_total_filter.vcf
vcftools --vcf output_total_filter.vcf --weir-fst-pop samplesSim1.txt --weir-fst-pop samplesSol1.txt --out fb_total_filter
Weir and Cockerham mean Fst estimate: 1
Weir and Cockerham weighted Fst estimate: 1
After filtering, kept 27579 out of a possible 27579 Sites

#Original fst estimate, just with no missing data (and no phased)
vcftools --vcf filter_no_missing.vcf --weir-fst-pop samplesSim1.txt --weir-fst-pop samplesSol1.txt --out fb_total_filter






#STARTING OVER AGAIN - JUNE 2020 and JULY
#RawReads directory in Spisula folder


#INITIALIZE
mkdir /workdir/hh693
cd /workdir/hh693
cp /home/mph75_0001/shared/Hannah/Spisula/MarkerDevelopment/* . &



#FASTQC
#FOR ORIGINALS AND TRIMMED



#BBMAP
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
export PATH=/programs/bbmap-38.73:$PATH

for SAMPLE in "${SAMPLES[@]}"; do
	echo "$SAMPLE"
	bbduk.sh in1=$SAMPLE'_R1.fastq.gz' in2=$SAMPLE'_R2.fastq.gz' out1=$SAMPLE'_clean_R1.fastq.gz' out2=$SAMPLE'_clean_R2.fastq.gz' ref=/programs/bbmap-38.73/resources/adapters.fa maq=10 ktrim=r k=23 mink=11 hdist=1 tpe tbo >& $SAMPLE'_bbmap.log'
done

#Pieces I want:
#Adapter trimming
#	ktrim=r k=23 mink=11 hdist=1 tpe tbo
#Mapping Quality
#	maq=10
#Minimum Length (maybe)
#	qtrim=r trimq=10 minlen=50
#Histogram Generate (maybe)
#	bhist=bhist.txt qhist=qhist.txt gchist=gchist.txt aqhist=aqhist.txt lhist=lhist.txt gcbins=auto
#Trims about 0.5% of bases/reads - could be more stringent but it works and is eliminating without 



#TRINITY POST BBMAP
#Edit the comments out of the script (SpisulaTrinity.sh), Similis vs Solidissima
chmod u+x Trinity_Solidissima.sh
nohup ./Trinity_Solidissima.sh >& Trinity_Sol.log &

chmod u+x Trinity_Similis.sh
nohup ./Trinity_Similis.sh >& Trinity_Sim.log &

tail -f Trinity_Sol.log



#TRINITY QC
#BUSCO
cp /programs/busco-3.1.0/config/config.ini ./ 
export BUSCO_CONFIG_FILE=/workdir/hh693/config.ini 
export PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packages 
export PATH=/programs/busco-3.1.0/scripts:$PATH 
tar xvfz metazoa_odb10.tar.gz 

run_BUSCO.py --in ./Trinity_Solidissima.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out trinityBUSCO_Solidissima -f >& BUSCO_log_sol.log &
run_BUSCO.py --in ./Trinity_Similis.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out trinityBUSCO_Similis -f >& BUSCO_log_sim.log &


#!/usr/local/bin/python2.7.15
generate_plot.py -wd run_trinityBUSCO_Solidissima
generate_plot.py -wd run_trinityBUSCO_Similis
#If that doesnt work: generate_plot.py -wd run_trinityBUSCO
#graph still not working

#BUSCO WITH MOLLUSCA
run_BUSCO.py --in ./Trinity_Solidissima.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 12 --out mollusca_Solidissima -f >& logs/BUSCO_mollusca_sol_t2.log &
run_BUSCO.py --in ./Trinity_Similis.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 12 --out mollusca_Similis -f >& logs/BUSCO_mollucsa_sim_t2.log &
#DID NOT WORK
generate_plot.py -wd run_BUSCOmollusca_Solidissima &
generate_plot.py -wd run_BUSCOmollusca_Similis &

#BLASTX 
makeblastdb -in uniprot_sprot.fasta -dbtype prot
blastx -query ./trinity_out_Solidissima/Trinity.fasta -db uniprot_sprot.fasta -out blastx_Sol.outfmt6 -evalue 1e-20 -num_threads 8 -max_target_seqs 1 -outfmt 6 &
blastx -query ./trinity_out_Similis/Trinity.fasta -db uniprot_sprot.fasta -out blastx_sim.outfmt6 -evalue 1e-20 -num_threads 8 -max_target_seqs 1 -outfmt 6 &

export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol.outfmt6 Trinity_Solidissima.fasta db_ref/uniprot_sprot.fasta
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_sim.outfmt6 Trinity_Similis.fasta db_ref/uniprot_sprot.fasta

#GENERAL STATS
export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/TrinityStats.pl Trinity_Similis.fasta
$TRINITY_HOME/util/TrinityStats.pl Trinity_Solidissima.fasta



#TRIM TRINITY
#ISOFORM SELECTION
# open Trinity.fasta.gene_trans_map in excel

grep ">" trinity_out_Solidissima/Trinity.fasta > sequenceheader_Sol

# open sequenceheader_Sol in excel
# replace len= with nothing
# replace > with nothing
# copy the isoform name and length into the map excel
# make sure isoforms map
# then data > sort, column A (gene) A to Z, column C (length) Largest to Smallest
# all columns and remove duplicates from column A
# save just the list of isoforms as a .txt

makeblastdb -in Trinity.fasta -dbtype nucl -parse_seqids
blastdbcmd -db Trinity.fasta -entry_batch LongestIso_Sol.txt -out Trinity_longiso.fasta


#REPEAT QC WITH ISOFORM TRIMMED
export BUSCO_CONFIG_FILE=/workdir/hh693/config.ini 
export PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packages 
export PATH=/programs/busco-3.1.0/scripts:$PATH 
run_BUSCO.py --in ./Trinity_iso_Sol.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOiso_Solidissima -f >& BUSCO_iso_sol.log &
blastx -query ./Trinity_iso_Sol.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sol_iso.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &

run_BUSCO.py --in ./Trinity_iso_Sol.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 8 --out BUSCOiso_Solidissima_Mollusc -f >& BUSCO_iso_moll_sol.log &

generate_plot.py -wd run_BUSCOiso_Solidissima

export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol_iso.outfmt6 Trinity_iso_Sol.fasta db_ref/uniprot_sprot.fasta
$TRINITY_HOME/util/TrinityStats.pl Trinity_iso_Sol.fasta



#CHOOSE REFERENCE
#Solidissima to keep code the same, even though isoformed, Sim is likely marginally better



#BWA PREPARE REF
#Rename and move if need be.
TMP=/workdir/$USER/tmp
GATKDIR=/programs/gatk-4.1.4.0
export PATH=$GATKDIR:$PATH
gatk CreateSequenceDictionary -R Sol_ref.fa  -O Sol_ref.dict
samtools faidx Sol_ref.fa
#Index for BWA alignment
bwa index Sol_ref.fa



#BWA ALIGN

# Basic script code (running it without script for now):
TMP=/workdir/$USER/tmp
GATKDIR=/programs/gatk-4.1.4.0
export PATH=$GATKDIR:$PATH
ACC=Sol10
SAM=Solidissima
REFFASTA=Sol_ref.fa

bwa mem -t 11  -R "@RG\tID:${ACC}\tSM:${ACC}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA ${ACC}_R1.fastq.gz ${ACC}_R2.fastq.gz | samtools view -Sb -@18 -o ${ACC}_iso_output.bam -



#MARK DUPLICATES
#SWITCH TO OLD JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH

GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

ACC=Sim5
SAM=Solidissima
REFFASTA=Sol_ref.fa

gatk MarkDuplicatesSpark \
-I ${ACC}_iso_output.bam \
-O ${ACC}.sorted.dedup.bam \
-M ${ACC}.sorted.dedup.txt \
--tmp-dir $TMP \
--conf "spark.executor.cores=7" \
>& sortdedup_${ACC}.log &



#HAPLOTYPE CALLER
#HAPLOTYPE CALL INDIVIDUALLY

#INITIALIZE JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
REFFASTA=./Sol_ref.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

ACCB=Sim4

gatk --java-options "-Xmx4g"  HaplotypeCaller \
    --tmp-dir $TMP \
     -R $REFFASTA \
     -I $ACCB.sorted.dedup.bam  \
     -ERC GVCF \
     --native-pair-hmm-threads 4 \
     --minimum-mapping-quality 30 \
     -O $ACCB_4.g.vcf >& hc4_$ACCB.log &


#Date: June 29 2020
#PARALELIZATION

samtools view -h Sim4_iso_output.bam | grep "@SQ" | less
118827
less Sim4_chromosomename | awk '{print $2}' > Sim4_chromosomename.txt

Sim4_chromosomename.txt
118827
000000
 10000
 
awk 'NR>=1&&NR<=10000' Sim4_chromosomename > Sim4_chrA.txt &
awk 'NR>=10000&&NR<=20000' Sim4_chromosomename > Sim4_chrB.txt &
awk 'NR>=20000&&NR<=30000' Sim4_chromosomename > Sim4_chrC.txt &
awk 'NR>=30000&&NR<=40000' Sim4_chromosomename > Sim4_chrD.txt &
awk 'NR>=40000&&NR<=50000' Sim4_chromosomename > Sim4_chrE.txt &
awk 'NR>=50000&&NR<=60000' Sim4_chromosomename > Sim4_chrF.txt &
awk 'NR>=60000&&NR<=70000' Sim4_chromosomename > Sim4_chrG.txt &
awk 'NR>=70000&&NR<=80000' Sim4_chromosomename > Sim4_chrH.txt &
awk 'NR>=80000&&NR<=90000' Sim4_chromosomename > Sim4_chrI.txt &
awk 'NR>=90000&&NR<=100000' Sim4_chromosomename > Sim4_chrJ.txt &
awk 'NR>=100000&&NR<=110000' Sim4_chromosomename > Sim4_chrK.txt &
awk 'NR>=110000&&NR<=118827' Sim4_chromosomename > Sim4_chrL.txt &


trinity_out_Solidissima/Trinity.fasta > sequenceheader_Sol


java -jar /programs/picard-tools-2.19.2/picard.jar FilterSamReads I=Sim4_iso_output.bam O=Sim4_chrA.bam READ_LIST_FILE=Sim4_chrA.txt FILTER=includeReadList &
#Took about 13 minutes


LETTERS=(
A
B
C
D
E
F
G
H
I
J
K
L
)
for i in "${LETTERS[@]}"; do
	echo "$i"
	java -jar /programs/picard-tools-2.19.2/picard.jar FilterSamReads I=Sim4.sorted.dedup.bam O='Sim4_chr'$i'.sorted.bam' READ_LIST_FILE='Sim4_chr'$i'.txt' FILTER=includeReadList &
done

#Super fast
parallel samtools index ::: *chr*sorted.bam

export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
REFFASTA=./Sol_ref.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

ACCB=Sim4
i=A
echo 'Sim4_chr'$i'.sorted.bam'

gatk --java-options "-Xmx4g"  HaplotypeCaller \
    --tmp-dir $TMP \
     -R $REFFASTA \
     -I 'Sim4_chr'$i'.sorted.bam'  \
     -ERC GVCF \
     --native-pair-hmm-threads 2 \
     --minimum-mapping-quality 30 \
     -O 'Sim4.chr'$i'.g.vcf' >& 'hc2_Sim4_chr'$i'.log' &


touch j_haplotypecall.txt

for i in "${LETTERS[@]}"; do
	echo "gatk --java-options "-Xmx4g"  HaplotypeCaller --tmp-dir $TMP -R $REFFASTA -I 'Sim4_chr'$i'.sorted.bam' -ERC GVCF --native-pair-hmm-threads 2 --minimum-mapping-quality 30 -O 'Sim4.chr'$i'.g.vcf' >& 'hc2_Sim4_chr'$i'.log' &" >> j_haplotypecall.txt
done

parallel -j 10 < j_haplotypecall.txt


#COMBINE GVCF
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
REFFASTA=./Sol_ref.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

# the gVCFG files obtained before need to be combined to be used with GenotypeGVCFs tool

echo Combining GVCFs started 
date

gatk CombineGVCFs \
     --tmp-dir $TMP \
     -R $REFFASTA \
     --variant Sim4.chrA.g.vcf \
     --variant Sim4.chrB.g.vcf \
     --variant Sim4.chrC.g.vcf \
     --variant Sim4.chrD.g.vcf \
     --variant Sim4.chrE.g.vcf \
     --variant Sim4.chrF.g.vcf \
     --variant Sim4.chrG.g.vcf \
     --variant Sim4.chrH.g.vcf \
     --variant Sim4.chrI.g.vcf \
     --variant Sim4.chrJ.g.vcf \
     --variant Sim4.chrK.g.vcf \
     --variant Sim4.chrL.g.vcf \
     -O Sim4_chr.g.vcf  >& all_Sim4_bychr_vcf.log &

cat Sim4.chrA.g.vcf Sim4.chrB.g.vcf Sim4.chrC.g.vcf Sim4.chrD.g.vcf Sim4.chrE.g.vcf Sim4.chrF.g.vcf Sim4.chrG.g.vcf Sim4.chrH.g.vcf Sim4.chrI.g.vcf Sim4.chrJ.g.vcf Sim4.chrK.g.vcf Sim4.chrL.g.vcf > Sim4_chr_cat.g.vcf

echo Run ended
date

#LIST OF ALL CHROMOSOMES TO DO GVCF BY REGION
grep ">" Sol_ref.fa | awk '{print $1}' | awk '{ print substr($0,2) }' > chr_list.txt

export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

rm j_combinegvcf.txt
touch j_combinegvcf.txt
COUNTER=0

while read REGION; do
echo $REGION
COUNTER=$[COUNTER + 1]
i=A
if [ $COUNTER -ge 10000 ]; then
i=B
fi
if [ $COUNTER -ge 20000 ]; then
i=C
fi
if [ $COUNTER -ge 30000 ]; then
i=D
fi
if [ $COUNTER -ge 40000 ]; then
i=E
fi
if [ $COUNTER -ge 50000 ]; then
i=F
fi
if [ $COUNTER -ge 60000 ]; then
i=G
fi
if [ $COUNTER -ge 70000 ]; then
i=H
fi
if [ $COUNTER -ge 80000 ]; then
i=I
fi
if [ $COUNTER -ge 90000 ]; then
i=J
fi
if [ $COUNTER -ge 100000 ]; then
i=K
fi
if [ $COUNTER -ge 110000 ]; then
i=L
fi
echo "gatk CombineGVCFs --tmp-dir $TMP -R Sol_ref.fa -L $REGION --variant Sim4.chr'$i'.g.vcf --variant Sim5.g.vcf --variant Sim6.g.vcf --variant Sol6.g.vcf --variant Sol7.g.vcf --variant Sol8.g.vcf --variant Sol10.g.vcf -O vcf_by_chr/'combine'_$REGION'.g.vcf' >& logs/'combinegcvf_chr_'$REGION'.log' " >> j_combinegvcf.txt
done < chr_list.txt


head -5 j_combinegvcf.txt > j_combine_head.txt
parallel -j 3 < j_combine_head.txt


gatk CombineGVCFs --tmp-dir $TMP -R Sol_ref.fa --variant Sim4_chr_cat.g.vcf --variant Sim5.g.vcf --variant Sim6.g.vcf --variant Sol6.g.vcf --variant Sol7.g.vcf --variant Sol8.g.vcf --variant Sol10.g.vcf -O ALL.g.vcf >& logs/ALL_combine.log &
1219

#Date: July 6 2020
#RE-INDEX THE g.VCFs
bgzip mySample1.g.vcf
tabix mySample1.g.vcf.gz

bgzip < Sim4.g.vcf > Sim4.g.vcf.gz &
bgzip < Sim5.g.vcf > Sim5.g.vcf.gz &
bgzip < Sim6.g.vcf > Sim6.g.vcf.gz &
bgzip < Sol6.g.vcf > Sol6.g.vcf.gz &
bgzip < Sol7.g.vcf > Sol7.g.vcf.gz &
bgzip < Sol8.g.vcf > Sol8.g.vcf.gz &
bgzip < Sol10.g.vcf > Sol10.g.vcf.gz &

tabix Sim4.g.vcf.gz &
tabix Sim5.g.vcf.gz &
tabix Sim6.g.vcf.gz &
tabix Sol6.g.vcf.gz &
tabix Sol7.g.vcf.gz &
tabix Sol8.g.vcf.gz &
tabix Sol10.g.vcf.gz &

#Produces .tbi file


#Combine g VCF
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp2
export PATH=$GATKDIR:$PATH
REFFASTA=Sol_ref.fa
gatk CombineGVCFs --tmp-dir $TMP -R $REFFASTA --variant Sim4.g.vcf.gz --variant Sim5.g.vcf.gz --variant Sim6.g.vcf.gz --variant Sol6.g.vcf.gz --variant Sol7.g.vcf.gz --variant Sol8.g.vcf.gz --variant Sol10.g.vcf.gz -O all.g.vcf.gz >& combine_g.log

#Combine by region
REGION=TRINITY_DN0_c0_g1_i13
gatk CombineGVCFs --tmp-dir $TMP -R $REFFASTA -L $REGION --variant Sim4.g.vcf.gz --variant Sim5.g.vcf.gz --variant Sim6.g.vcf.gz --variant Sol6.g.vcf.gz --variant Sol7.g.vcf.gz --variant Sol8.g.vcf.gz --variant Sol10.g.vcf.gz -O all_$REGION.g.vcf.gz >& combine_$REGION.log


export PATH=/programs/bcftools-1.9/bin:$PATH
CHR=TRINITY_DN0_c0_g2_i1
bcftools view -r $CHR Sim4.g.vcf.gz -O z -o Sim4.$CHR.g.vcf.gz
bcftools view -r $CHR Sim5.g.vcf.gz -O z -o Sim5.$CHR.g.vcf.gz
bcftools view -r $CHR Sim6.g.vcf.gz -O z -o Sim6.$CHR.g.vcf.gz
bcftools view -r $CHR Sol6.g.vcf.gz -O z -o Sol6.$CHR.g.vcf.gz
bcftools view -r $CHR Sol7.g.vcf.gz -O z -o Sol7.$CHR.g.vcf.gz
bcftools view -r $CHR Sol8.g.vcf.gz -O z -o Sol8.$CHR.g.vcf.gz
bcftools view -r $CHR Sol10.g.vcf.gz -O z -o Sol10.$CHR.g.vcf.gz

tabix Sim4.$CHR.g.vcf.gz &
tabix Sim5.$CHR.g.vcf.gz &
tabix Sim6.$CHR.g.vcf.gz &
tabix Sol6.$CHR.g.vcf.gz &
tabix Sol7.$CHR.g.vcf.gz &
tabix Sol8.$CHR.g.vcf.gz &
tabix Sol10.$CHR.g.vcf.gz &

gatk CombineGVCFs --tmp-dir $TMP -R $REFFASTA --variant Sim4.$CHR.g.vcf.gz --variant Sim5.$CHR.g.vcf.gz --variant Sim6.$CHR.g.vcf.gz --variant Sol6.$CHR.g.vcf.gz --variant Sol7.$CHR.g.vcf.gz --variant Sol8.$CHR.g.vcf.gz --variant Sol10.$CHR.g.vcf.gz -O all_$CHR.g.vcf.gz >& combine_gz_$CHR.log




gatk CombineGVCFs --tmp-dir $TMP -R $REFFASTA --variant Sim4.$CHR.g.vcf --variant Sim5.$CHR.g.vcf --variant Sim6.$CHR.g.vcf --variant Sol6.$CHR.g.vcf --variant Sol7.$CHR.g.vcf --variant Sol8.$CHR.g.vcf --variant Sol10.$CHR.g.vcf -O all.$CHR.g.vcf >& combine_g.$CHR.log


#Date: July 21 2020

#DataBase
gatk --java-options "-Xmx4g -Xms4g" GenomicsDBImport \
      -V Sim4.g.vcf.gz \
      -V Sim5.g.vcf.gz \
      -V Sim6.g.vcf.gz \
      -V Sol8.g.vcf.gz \
      -V Sol7.g.vcf.gz \
      -V Sol6.g.vcf.gz \
      -V Sol10.g.vcf.gz \
      --genomicsdb-workspace-path spisula_db \
      --tmp-dir=tmp2 \
      -L 20

#Change headers so sample names are different
#What if that is the problem
#RENAME

bcftools reheader --help


SAMPLE=Sol7
echo "Solidissima Sim5" > samplename.txt
bcftools reheader -s samplename.txt Sim5.g.vcf.gz -o Sim5_r.g.vcf.gz
bcftools query -l Sim5_r.g.vcf.gz 



bcftools reheader -s samplename.txt Sol10.g.vcf.gz -o Sol10_r.g.vcf.gz



tabix Sim4_r.g.vcf.gz &
tabix Sim5_r.g.vcf.gz &
tabix Sim6_r.g.vcf.gz &
tabix Sol6_r.g.vcf.gz &
tabix Sol7_r.g.vcf.gz &
tabix Sol8_r.g.vcf.gz &
tabix Sol10_r.g.vcf.gz &


gatk --java-options "-Xmx4g -Xms4g" GenomicsDBImport -V Sim4_r.g.vcf.gz -V Sim5_r.g.vcf.gz -V Sim6_r.g.vcf.gz -V Sol8_r.g.vcf.gz -V Sol7_r.g.vcf.gz -V Sol6_r.g.vcf.gz -V Sol10_r.g.vcf.gz --genomicsdb-workspace-path spisula_db --tmp-dir=tmp2 -L20
#NOT WORKING NEED L for INDEX but L=20 default doesn't work



GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp2
export PATH=$GATKDIR:$PATH
REFFASTA=Sol_ref.fa
CHR=TRINITY_DN10_c1_g1_i7
gatk CombineGVCFs --tmp-dir $TMP -R $REFFASTA -L $CHR --variant Sim4_r.g.vcf.gz --variant Sim5_r.g.vcf.gz --variant Sim6_r.g.vcf.gz --variant Sol6_r.g.vcf.gz --variant Sol7_r.g.vcf.gz --variant Sol8_r.g.vcf.gz --variant Sol10_r.g.vcf.gz -O all_$CHR.g.vcf.gz >& combine_$CHR.log

gunzip -c Sim4_r.g.vcf.gz > Sim4_r.g.vcf
gunzip -c Sim5_r.g.vcf.gz > Sim5_r.g.vcf &
gunzip -c Sim6_r.g.vcf.gz > Sim6_r.g.vcf &
gunzip -c Sol6_r.g.vcf.gz > Sol6_r.g.vcf &
gunzip -c Sol7_r.g.vcf.gz > Sol7_r.g.vcf &
gunzip -c Sol8_r.g.vcf.gz > Sol8_r.g.vcf &
gunzip -c Sol10_r.g.vcf.gz > Sol10_r.g.vcf &

gatk IndexFeatureFile -F Sol10_r.g.vcf &


#Adjust headers
#OR
#FreeBayes

FB=/programs/freebayes-v1.3.1/freebayes

REFFASTA=./genome/genome.fa

echo Started at
date
$FB -f $REFFASTA \
SRR1663608.sorted.dedup.bam \
SRR1663609.sorted.dedup.bam \
SRR1663610.sorted.dedup.bam \
SRR1663611.sorted.dedup.bam \
--min-mapping-quality 30 \
-r chr2R > fb.vcf
echo Completed at
date


#ADJUST HEADERS OF BAM FILES
samtools view -H Sim4.sorted.dedup.bam | grep "@SQ" | less
samtools view -H Sim4.sorted.dedup.bam | grep -v "@SQ" | less

FB=/programs/freebayes-v1.3.1/freebayes
REFFASTA=Sol_ref.fa
REGION=TRINITY_DN100_c0_g1_i11

$FB -f $REFFASTA \
Sim4.sorted.dedup.bam \
Sim5.sorted.dedup.bam \
Sim6.sorted.dedup.bam \
Sol6.sorted.dedup.bam \
Sol7.sorted.dedup.bam \
Sol8.sorted.dedup.bam \
Sol10.sorted.dedup.bam \
--min-mapping-quality 30 \
-r $REGION > fb_$REGION.vcf >& fb_$REGION.log &

TY_DN100_c0_g1_i11 2       .       C       A       6.55747e-14     .       AB=0;ABP=0;AC=0;AF=0;AN=2;AO=5;CIGAR=1X;DP=55;DPB=55;DPRA=0;EPP=6.91895;EPPR=5.18177;GTI=0;LEN=1;MEANALT=2;MQM=40.4;MQMR=39.9184;NS=1;NUMALT=1;ODDS=37.5659;PAIRED=0.2;PAIREDR=0.367347;PAO=0;PQA=0;PQR=0;PRO=0;QA=176;QR=1678;RO=49;RPL=0;RPP=13.8677;RPPR=109.412;RPR=5;RUN=1;SAF=1;SAP=6.91895;SAR=4;SRF=21;SRP=5.18177;SRR=28;TYPE=snp;technology.ILLUMINA=1        GT:DP:AD:RO:QR:AO:QA:GL 0/0:55:49,5:49:1678:5:176:0,-1.44155,-125.602

@HD     VN:1.6  GO:none SO:coordinate
@RG     ID:Sim4 SM:Sim4  LB:Solidissima  PL:ILLUMINA
@PG     ID:bwa  PN:bwa  VN:0.7.17-r1188 CL:bwa mem -t 18 -R @RG\tID:Sim4\tSM:Sim4\tLB:Solidissima\tPL:ILLUMINA Sol_ref.fa Sim4_R1.fastq.gz Sim4_R2.fastq.gz

#Replace header
samtools view Sim4.sorted.dedup.bam


SM:Sim4
SM:Solidissima

SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)

for SAMPLE in "${SAMPLES[@]}"; do

for SAMPLE in "${SAMPLES[@]}"
do
	 BAM=$SAMPLE.sorted.dedup.bam
     samtools view -H $BAM > header.sam
     sed "s/SM:Solidissima/SM:$SAMPLE/" header.sam > header_corrected.sam
     samtools reheader  header_corrected.sam $BAM
done


for SAMPLE in "${SAMPLES[@]}"
do
samtools view -H $BAM | sed "s/Solid5500XL/Solid/" | samtools reheader - $BAM
done

for SAMPLE in "${SAMPLES[@]}"
do
samtools view -h $SAMPLE.sd.sam | sed "s/SM:Solidissima/SM:$SAMPLE/" > 
done


#Try converting to sam first
samtools view -h Sol10.sorted.dedup.bam > Sol10.sd.sam &
samtools view -h Sol6.sorted.dedup.bam > Sol6.sd.sam &
samtools view -h Sol7.sorted.dedup.bam > Sol7.sd.sam &
samtools view -h Sol8.sorted.dedup.bam > Sol8.sd.sam &
samtools view -h Sim6.sorted.dedup.bam > Sim6.sd.sam &
samtools view -h Sim5.sorted.dedup.bam > Sim5.sd.sam &
samtools view -h Sim4.sorted.dedup.bam > Sim4.sd.sam &

for SAMPLE in "${SAMPLES[@]}"
do
echo "samtools view -h $SAMPLE.sd.sam | sed "s/SM:Solidissima/SM:$SAMPLE/" | samtools view -S -b -o $SAMPLE.sd.bam"
done

for SAMPLE in "${SAMPLES[@]}"
do
echo "samtools index -@ 3 $SAMPLE.sd.bam"
done

#Job list over night

samtools view -h Sim4.sd.sam | sed s/SM:Solidissima/SM:Sim4/ | samtools view -S -b -o Sim4.sd.bam
samtools view -h Sim5.sd.sam | sed s/SM:Solidissima/SM:Sim5/ | samtools view -S -b -o Sim5.sd.bam
samtools view -h Sim6.sd.sam | sed s/SM:Solidissima/SM:Sim6/ | samtools view -S -b -o Sim6.sd.bam
samtools view -h Sol10.sd.sam | sed s/SM:Solidissima/SM:Sol10/ | samtools view -S -b -o Sol10.sd.bam
samtools view -h Sol8.sd.sam | sed s/SM:Solidissima/SM:Sol8/ | samtools view -S -b -o Sol8.sd.bam
samtools view -h Sol7.sd.sam | sed s/SM:Solidissima/SM:Sol7/ | samtools view -S -b -o Sol7.sd.bam
samtools view -h Sol6.sd.sam | sed s/SM:Solidissima/SM:Sol6/ | samtools view -S -b -o Sol6.sd.bam
samtools index -@ 3 Sim4.sd.bam
samtools index -@ 3 Sim5.sd.bam
samtools index -@ 3 Sim6.sd.bam
samtools index -@ 3 Sol10.sd.bam
samtools index -@ 3 Sol8.sd.bam
samtools index -@ 3 Sol7.sd.bam
samtools index -@ 3 Sol6.sd.bam
wait
FB=/programs/freebayes-v1.3.1/freebayes
REFFASTA=Sol_ref.fa
REGION=TRINITY_DN1001_c11_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.log &
REGION=TRINITY_DN100100_c0_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.txt &
REGION=TRINITY_DN100111_c0_g1_i1
$FB -f $REFFASTA Sim4.qsd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.log &
REGION=TRINITY_DN100111_c1_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.vcf >& fb_$REGION.log &
REGION=TRINITY_DN100111_c2_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.vcf >& fb_$REGION.log &
REGION=TRINITY_DN100111_c3_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.vcf >& fb_$REGION.log &
REGION=TRINITY_DN100111_c4_g1_i1
$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_$REGION.vcf >& fb_$REGION.log &

parallel -j4 < j_samHead_to_bam.txt

for REGION in "${SAMPLES[@]}"
do
echo "samtools index -@ 3 $SAMPLE.sd.bam"
done

while read REGION; do
  echo "echo $REGION"
  echo "$FB -f $REFFASTA Sim4.sd.bam Sim5.sd.bam Sim6.sd.bam Sol6.sd.bam Sol7.sd.bam Sol8.sd.bam Sol10.sd.bam --min-mapping-quality 30 -r $REGION > fb_vcf/fb_$REGION.vcf"
done <chr_list.txt > j_fb_contig.txt


parallel -j20 < j_fb_contig.txt


#CONCATENATE THEM TOGETHER
touch output.vcf
#One with header
cat fb_TRINITY_DN100_c0_g1_i11.log >> output.vcf  
#OR
grep "#" fb_TRINITY_DN100_c0_g1_i11.log | cat >> output.vcf 
#Then everybody else
grep -v "#" fb_TRINITY_DN1001*.log | cat >> output.vcf

#Looks good, make sure wc is good and that all the collumns are in the same order
23+18+186 = 227 CHECK
#Random sample across all fb_vcf indicates they are all in the same order.

#First do ten of them
#Don't forget the \ around internal quotes
for i in {0..9}
do
echo "echo $i"
echo "touch fb_vcf/output_DN$i.vcf"
echo "grep \"#\" fb_vcf/fb_TRINITY_DN0_c2_g1_i1.vcf | cat >> fb_vcf/output_DN$i.vcf"
echo "grep -v \"#\" fb_vcf/fb_TRINITY_DN$i*.vcf | cat >> fb_vcf/output_DN$i.vcf"
done > j_combine_fb_vcf.txt

screen
parallel -j16 < j_combine_fb_vcf.txt

#Checked to make sure they had all finished by doing tail -300+ to make sure there were 9s

#All in one
touch output_all.vcf
grep \"#\" output_DN1.vcf | cat >> output_all.vcf
grep -v \"#\" output_DN*.vcf | cat >> output_all.vcf



#FILTERING
#
grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | less
grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | head | less
#
grep -v "##" output_DN0.vcf | awk '{ {print $1} }' | less
grep -v "#" output_DN0.vcf | awk '{ {print $6} }' | sort -nrk1,1 | head -1


nohup ./scripts/filter_vcf.sh output_DN0 >& filter_vcf.log &
#Filtered everything - might be gatk vs freebayes difference
awk '{if($7=="PASS") print}' all.filtered.vcf | wc -l

#awk, starts with
grep -v "##" output_DN0.vcf | awk '{if($10 ~ "1/1") {print $10} }' | less

#Which ones need to match?
Sol10 = 10			Sim5 = 11
Sol7 = 12			Sim4 = 13
Sol6 = 15			Sim6 = 14
Sol8 = 16

grep -v "##" output_DN0.vcf | awk '{if(\
$10 ~ "0/0" &&\
$12 ~ "0/0" &&\
$15 ~ "0/0" &&\
$16 ~ "0/0" &&\
$11 ~ "1/1" &&\
$13 ~ "1/1" &&\
$14 ~ "1/1"\
) {print $7,$10,$11,$12,$13,$14,$15,$16} }' | less


grep -v "##" output_DN0.vcf | awk '{if(\
$10 ~ "0/0" &&\
$12 ~ "0/0" &&\
$15 ~ "0/0" &&\
$16 ~ "0/0" &&\
$11 ~ "1/1" &&\
$13 ~ "1/1" &&\
$14 ~ "1/1"\
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' | less


#REMOVE FILE NAME FROM CHR
grep -v "##" output_DN0.vcf | sed 's/fb_vcf.*vcf://g' | less
#Why does this not find the thing?
#Because in sed, * is single character, .* is string

#Use this for the individuals
sed 's/fb_vcf.*vcf://g' output_all.vcf > output_DN_all.vcf
#Use this for the all
sed 's/out.*vcf://g' output_all.vcf > output_DN_all.vcf


grep -v "##" output_DN_all.vcf | less
#MY OUTPUT ALL FILE HAS TEN HEADER LINES
cat -n output_DN_all.vcf | sort -uk2 | sort -n | cut -f2- > output_DN_lesshead.vcf

#1/1 AND 0/0 NO 0/1
#PHASING IS THE SAME
#This filtering also removes instances of missing data

#Sorted for both
grep "#" output_DN_lesshead.vcf > output_filter_1100.vcf
#Filtered one at a time to track which matches ref
grep "#" output_DN_lesshead.vcf > o_filter_Sim1_Sol0.vcf
grep "#" output_DN_lesshead.vcf > o_filter_Sim0_Sol1.vcf

#FIX TAB DELIMETER
grep "#" output_DN_lesshead.vcf > o_filter_Sim1_Sol0.vcf
awk 'BEGIN{FS=OFS="\t"}{if(\
$10 ~ "0/0" &&\
$12 ~ "0/0" &&\
$15 ~ "0/0" &&\
$16 ~ "0/0" &&\
$11 ~ "1/1" &&\
$13 ~ "1/1" &&\
$14 ~ "1/1"\
) {print} }' output_DN_all.vcf >> o_filter_Sim1_Sol0.vcf &

awk 'BEGIN{FS=OFS="\t"}{if(\
$10 ~ "1/1" &&\
$12 ~ "1/1" &&\
$15 ~ "1/1" &&\
$16 ~ "1/1" &&\
$11 ~ "0/0" &&\
$13 ~ "0/0" &&\
$14 ~ "0/0"\
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' output_DN_all.vcf >>  o_filter_Sim0_Sol1.vcf &

#PHASED
#Filtered one at a time to track which matches ref
grep "#" output_DN_lesshead.vcf > o_filter_Sim1_Sol0_phased.vcf
grep "#" output_DN_lesshead.vcf > o_filter_Sim0_Sol1_phased.vcf
grep "#" output_DN_lesshead.vcf > o_filter_Sim1_Sol0_phased_p.vcf

grep "#" o_filter_Sim1_Sol0.vcf > filter_no_missing.vcf
awk 'BEGIN{FS=OFS="\t"}{if(\
($10 ~ "0/0" || $10 ~ "1/1") &&\
($12 ~ "0/0" || $12 ~ "1/1") &&\
($15 ~ "0/0" || $15 ~ "1/1") &&\
($16 ~ "0/0" || $16 ~ "1/1") &&\
($11 ~ "1/1" || $11 ~ "0/0") &&\
($13 ~ "1/1" || $13 ~ "0/0") &&\
($14 ~ "1/1" || $14 ~ "0/0") \
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' output_DN_all.vcf>> filter_no_missing.vcf

awk 'BEGIN{FS=OFS="\t"}{if(\
($10 ~ "1/1" || $10 ~ "1|1") &&\
($12 ~ "1/1" || $12 ~ "1|1") &&\
($15 ~ "1/1" || $15 ~ "1|1") &&\
($16 ~ "1/1" || $16 ~ "1|1") &&\
($11 ~ "0/0" || $11 ~ "0|0") &&\
($13 ~ "0/0" || $13 ~ "0|0") &&\
($14 ~ "0/0" || $14 ~ "0|0") \
) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' output_all_unphased.vcf >>  o_filter_Sim0_Sol1_phased.vcf

awk 'BEGIN{FS=OFS="\t"}{if(\
($10 ~ "1/1")\
) {print $1,$10} }' output_DN_all.vcf | less

grep -v "##" output_DN_all.vcf | wc -l
2815714 OR -v "#" 2815704
grep -v "##" output_DN_lesshead.vcf | wc -l
Expecting 2815705 YES
grep -v "##" output_filter_1100.vcf | wc -l
86025 OR -v "#" 86024

grep -v "##" o_filter_Sim1_Sol0_phased.vcf | wc -l
1619557
grep -v "##" o_filter_Sim0_Sol1_phased.vcf | wc -l
1406293
#ADDS TO MORE THAN THE TOTAL??
#THE | SEEMS TO ACT AS A WILD CARD

sed 's/[|]/p/g' output_DN_all.vcf > output_all_unphased.vcf
grep -v "##" o_filter_Sim1_Sol0_phased_p.vcf | wc -l
85955
#DOES NOT ADD ANYTHING - INFACT IM NOT SURE THERE ARE ANY

grep -v "##" o_filter_Sim1_Sol0.vcf | wc -l
85955
grep -v "##" o_filter_Sim0_Sol1.vcf | wc -l
71
#THIS MAKES SENSE, MOST SITES THE SIMILIS IS DIFFERENT AND SOL MATCHES

grep -v "##" output_filter_1100.vcf | less
grep -v "##" output_DN_all.vcf | less


#FILTER BY QUALITY OR OTHER METRICS
#How many are lost when minumum quality is 100
awk '{if($6 > 100) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' o_filter_Sim1_Sol0.vcf | grep -v "#" | wc -l
81550
#Not a big loss
awk '{if($6 > 30) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' o_filter_Sim1_Sol0.vcf | wc -l
85079
awk '{if($6 > 1000) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' o_filter_Sim1_Sol0.vcf | wc -l
53421

bgzip -c o_filter_Sim1_Sol0.vcf > o_filter_Sim1_Sol0.vcf.gz
bcftools index o_filter_Sim1_Sol0.vcf.gz
bcftools stats --depth 1,2000,1 --samples-file samplelist.txt o_filter_Sim1_Sol0.vcf.gz  > o_filter_Sim1_Sol0.vcf.vchk 2> output_Sim1Sol0.stats.vchk.err

bcftools filter --include 'MIN(FORMAT/DP)>10' o_tab_S1S0.vcf | grep -v "##" | wc -l
27k <- individual
bcftools filter --include 'MIN(INFO/DP)>10' o_tab_S1S0.vcf | grep -v "##" | wc -l
85k <- group 
bcftools filter --include 'INFO/DP>200' o_tab_S1S0.vcf | grep -v "##" | wc -l
39253
bcftools filter --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | grep -v "##" | wc -l
34028

bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'TYPE="snp"' | grep -v "##" | wc -l
bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' | grep -v "##" | wc -l
27580
#NOTE PUTTING A CAP ON THE QUALITY REMOVES A LOT


#FILTERING FOR FST
#Date: August 16 2020
#WHICH ONE SHOULD I REMOVE?

Sim4
Sim5
Sim6
Sol6
Sol7
Sol8
Sol10
  
SAMPLES=(
CUP_265
CUP_352
GA_007
GA_008
MCX_082
PEC_011
SHN_126
TEST_010
)
vcftools --vcf pilot_unfiltered.vcf --out pilot.missing.test.vcf --missing-indv &
vcftools --vcf original_unfiltered.vcf --out original.missing.test.vcf --missing-indv &

Sol10   2815704 0       231832  0.0823354
Sim5    2815704 0       287434  0.102082
Sol7    2815704 0       239953  0.0852195
Sim4    2815704 0       180516  0.0641104
Sim6    2815704 0       476204  0.169124
Sol6    2815704 0       120372  0.0427502
Sol8    2815704 0       231284  0.0821407

INDV    N_DATA  N_GENOTYPES_FILTERED    N_MISS  F_MISS
TEST    264850  0       82112   0.310032
CUP_265 264850  0       85360   0.322296
PEC_011 264850  0       104600  0.394941     
MCX_082 264850  0       82110   0.310025
GA_007  264850  0       79441   0.299947
SHN_126 264850  0       84276   0.318203
CUP_352 264850  0       88483   0.334087
GA_008  264850  0       83516   0.315333
Sol10   2815704 0       231832  0.0823354
Sim5    2815704 0       287434  0.102082
Sol7    2815704 0       239953  0.0852195
Sim4    2815704 0       180516  0.0641104
Sim6    2815704 0       476204  0.169124
Sol6    2815704 0       120372  0.0427502
Sol8    2815704 0       231284  0.0821407

--missing-indv
#Generates a file reporting the missingness on a per-individual basis. The file has the suffix ".imiss".
--missing site
vcftools --vcf original_unfiltered.vcf --out original.missing.site.vcf --missing-site &
vcftools --vcf pilot_unfiltered.vcf --out pilot.missing.site.vcf --missing-site &

#Stats 
bcftools stats --depth 1,2000,1 --samples-file pilotlist pilot_unfiltered.vcf  > pilot.stats.vchk 2> pilot.stats.vchk.err &
bcftools stats --depth 1,2000,1 --samples-file originallist original_unfiltered.vcf  > original.stats.vchk 2> original.stats.vchk.err &
#These are showing up as almost all depth 1! Like 98 %. Where is the original one and what did it say?
bgzip -c o_filter_Sim1_Sol0.vcf > o_filter_Sim1_Sol0.vcf.gz
bcftools index o_filter_Sim1_Sol0.vcf.gz
bcftools stats --depth 1,2000,1 --samples-file originallist o_filter_Sim1_Sol0.vcf.gz  > o_filter_Sim1_Sol0.vcf.vchk 2> output_Sim1Sol0.stats.vchk.err
#I might have been looking at the genotypes rather than the site
#The depth for sites are still fairly low - there are a couple thousand greater than 80, a couple hundred >200, the biggest is 948
grep "DP" pilot.stats.vchk > pilot_DP_stats.txt
grep "DP" original.stats.vchk > original_DP_stats.txt

grep "QUAL" pilot.stats.vchk > pilot_QUAL_stats.txt
grep "QUAL" original.stats.vchk > original_QUAL_stats.txt

#DENSITY DIAGRAMS?
#Use the GQ rather than QUAL - confirm they are different
TRINITY_DN0_c0_g1_i13   44      .       GTTTG   TTTTT   377998  .       AB=0;ABP=0;AC=14;AF=1;AN=14;AO=20857;CIGAR=1X3M1X;DP=22052;DPB=22037;DPRA=0;EPP=44360.2;EPPR=334.096;GTI=0;LEN=5;MEANALT=33.8571;MQM=33.2603;MQMR=47.307;NS=7;NUMALT=1;ODDS=2269.69;PAIRED=0.0311646;PAIREDR=0.284926;PAO=2;PQA=14;PQR=70;PRO=5;QA=716686;QR=9251;RO=544;RPL=20857;RPP=45293.4;RPPR=648.081;RPR=0;RUN=1;SAF=20749;SAP=44360.2;SAR=108;SRF=429;SRP=396.574;SRR=115;TYPE=complex;technology.ILLUMINA=1    GT:DP:AD:RO:QR:AO:QA:GL 1/1:1408:24,1331:24:373:1331:45958:-3607.92,-374.419,0  1/1:1494:39,1404:39:632:1404:48015:-3761,-377.57,0      1/1:2391:53,2275:53:903:2275:78013:-6097.63,-620.089,0  1/1:4521:137,4227:137:2353:4227:145286:-11283.5,-1102.49,0      1/1:5359:129,5092:129:2231:5092:175211:-13658.9,-1371.45,0      1/1:4078:116,3843:116:2018:3843:131648:-10236.1,-1010.92,0      1/1:2801:46,2685:46:741:2685:92555:-7252.87,-755.459,0

#FROM FREEBAYES GITHUB:
"Of primary interest to most users is the QUAL field, which estimates the probability 
that there is a polymorphism at the loci described by the record. In freebayes, this value 
can be understood as 1 - P(locus is homozygous given the data). It is recommended that 
users use this value to filter their results, rather than accepting anything output by 
freebayes as ground truth."
"freebayes estimates observation quality using several simple heuristics based on manipulations of the phred-scaled base qualities:
For single-base observations, mismatches and reference observations: the un-adjusted base quality provided in the BAM alignment record.
For insertions: the mean quality of the bases inside of the putatively inserted sequence.
For deletions: the mean quality of the bases flanking the putatively deleted sequence.
For haplotypes: the mean quality of allele observations within the haplotype.
By default, both base and mapping quality are into the reported site quality (QUAL in the VCF) and genotype quality (GQ, when supplying --genotype-qualities). This integration is driven by the "Effective Base Depth" metric first developed in snpTools, which scales observation quality by mapping quality: P(Obs|Genotype) ~ P(MappedCorrectly(Obs))P(SequencedCorrectly(Obs)). Set --standard-gls to use the model described in the freebayes preprint."


#What is another way to look that the missing individual - Fastq files?
#I could also try removing each one and seeing what results that gives.



#Cross reference for same alleles




#Filtering
bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' pilot_unfiltered.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' | grep -v "##" | wc -l








#CHART
#TOTAL
2,815,704
#NO MISSING AND NO PHASED
307,735
#DIANOGSTIC
85,954
#DEPTH (200-1500)
34,028
#DISTANCE FROM INDELS 
33,468
#SNPs only
27,830


awk '{if($6 > 100 && ) {print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16} }' o_filter_Sim1_Sol0.vcf | wc -l


bcftools filter --SnpGap 20 --include 'INFO/DP>200 && INFO/DP<2000' o_tab_S1S0.vcf | bcftools filter --include 'QUAL>100' | bcftools filter --include 'TYPE="snp"' > output_total_filter.vcf
vcftools --vcf output_total_filter.vcf --weir-fst-pop samplesSim1.txt --weir-fst-pop samplesSol1.txt --out fb_total_filter
Weir and Cockerham mean Fst estimate: 1
Weir and Cockerham weighted Fst estimate: 1
After filtering, kept 27579 out of a possible 27579 Sites

#Original fst estimate, just with no missing data (and no phased)
vcftools --vcf filter_no_missing.vcf --weir-fst-pop samplesSim1.txt --weir-fst-pop samplesSol1.txt --out fb_total_filter




#FIX THE VCFTOOLS NOT LIKING THE HEASDER
#Quick workaround: index the file with tabix
#first compress - ERROR: Failed to parse TBX_VCF, was wrong -p [type] used?
#CAUSE THESE ONES ARE STILL NOT TAB-DELIMETERED

o_filter_Sim1_Sol0.vcf
grep "#" o_filter_Sim1_Sol0.vcf > o_tab_S1S0.vcf
grep -v "#" o_filter_Sim1_Sol0.vcf | tr " " "\t" >> o_tab_S1S0.vcf

bgzip -c o_tab_S1S0.vcf > o_tab_S1S0.vcf.gz


samtools flagstat Sim6_iso_ouput.bam

























##############################################################


#PREVIOUS WORK

#Citation for parallel
#O. Tange (2011): GNU Parallel - The Command-Line Power Tool,
#  ;login: The USENIX Magazine, February 2011:42-47.

sed s/^.* fb_vcf/fb_*.vcf:
sed 's/foo/bar/g' hello.txt
sed 's/fb_vcf*:/bar/g' 

grep -v "##" output_DN0.vcf | sed 's/^.*fb_vcf*:/t/g' | less
grep -v "##" output_DN0.vcf |sed 's/fb_vcf.*vcf://g' | less


grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | head | less


grep -v "#" Sim6.g.vcf.gz | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }'  | less
| grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | less


less Sim6.g.vcf.gz |grep -v "#" | less | wc -l
7529777

less Sim4_chr_cat.g.vcf.gz | grep -v "#" | less | wc -l
1425924 
#APPEARS TO SHOW NO DIFFERENCE FROM REFERENCE


generate_plot.py -wd run_BUSCOiso_Solidissima_Mollusc

grep -v "#" Sim4.g.vcf | wc -l
416874
grep -v "#" Sim5.g.vcf | wc -l
3263157
grep -v "#" Sim6.g.vcf | wc -l
799007
#Rerun 4 and 6 because they were done without the java lines. 


grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | less
grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | grep "0/1" | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | wc -l
grep -v "#" Sim4.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | awk ' {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} ' | wc -l


#All	#0/0	#1/1	#0/1	#0|0	#1|1	#All without Q>100 filtering
31457	25495	1102	1300	104		1585	39666


################ RUN LINES #####################
grep -v "#" Sim.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' > Sim.test.vcf
grep "1/1" Sim.test.vcf | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' > Sim.filter.vcf
grep -v "#" Sol.g.vcf > Sol.test.vcf 

export OMP_NUM_THREADS=16

/programs//R-3.5.0s/bin/R
#install.packages("tidyverse")
library("tidyverse")
Sol <- read.table("Sol.test.vcf")
Sim <- read.table("Sim.filter.vcf")
Sim["V11"] = "P"

for (i in 1:nrow(Sol)) {
chrom <- Sol[i,1]
pos <- Sol[i,2]
for (j in 1:nrow(Sim)) {
if (Sim[j,1]==chrom & Sim[j,2]==pos) {
Sim[j,4] <- NA
}
}
}



#MISC NOTES OF THINGS THAT DIDNT WORK
# nohup ./HGH_bwa_aln.sh >& bwa_aln_all.log &
#bwa mem -M -t 18 -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA ${ACC}_clean_R1.fastq.gz  ${ACC}_clean_R2.fastq.gz > $ACC_i.sam
# | samtools view -Sb - > $ACC_i.bam
#4700.661 sec; CPU: 40764.924 sec
#Sim4
#Real time: 2791.894 sec; CPU: 46231.244 sec

# nohup at the beginning does not work for bwa mem
#SET WITHIN FUNCTION OR IT IGNORES INPUT

#QC RESULTS

#TRINITY QC
#BUSCO
cp /programs/busco-3.1.0/config/config.ini ./ 
export BUSCO_CONFIG_FILE=/workdir/hh693/config.ini 
export PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packages 
export PATH=/programs/busco-3.1.0/scripts:$PATH 
tar xvfz metazoa_odb10.tar.gz 

run_BUSCO.py --in ./Trinity_Solidissima.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out trinityBUSCO_Solidissima -f >& BUSCO_log_sol.log &
run_BUSCO.py --in ./Trinity_Similis.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out trinityBUSCO_Similis -f >& BUSCO_log_sim.log &


#!/usr/local/bin/python2.7.15
generate_plot.py -wd run_trinityBUSCO_Solidissima
generate_plot.py -wd run_trinityBUSCO_Similis
#If that doesnt work: generate_plot.py -wd run_trinityBUSCO
#graph still not working

#BUSCO WITH MOLLUSCA
run_BUSCO.py --in ./Trinity_Solidissima.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 12 --out mollusca_Solidissima -f >& logs/BUSCO_mollusca_sol_t2.log &
run_BUSCO.py --in ./Trinity_Similis.fasta --lineage_path ./db_ref/mollusca_odb10 --mode transcriptome --cpu 12 --out mollusca_Similis -f >& logs/BUSCO_mollucsa_sim_t2.log &
#DID NOT WORK
generate_plot.py -wd run_BUSCOmollusca_Solidissima &
generate_plot.py -wd run_BUSCOmollusca_Similis &

#BLASTX 
makeblastdb -in uniprot_sprot.fasta -dbtype prot
blastx -query ./trinity_out_Solidissima/Trinity.fasta -db uniprot_sprot.fasta -out blastx_Sol.outfmt6 -evalue 1e-20 -num_threads 8 -max_target_seqs 1 -outfmt 6 &
blastx -query ./trinity_out_Similis/Trinity.fasta -db uniprot_sprot.fasta -out blastx_sim.outfmt6 -evalue 1e-20 -num_threads 8 -max_target_seqs 1 -outfmt 6 &

export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol.outfmt6 Trinity_Solidissima.fasta db_ref/uniprot_sprot.fasta
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_sim.outfmt6 Trinity_Similis.fasta db_ref/uniprot_sprot.fasta

Sol
#hit_pct_cov_bin	count_in_bin	>bin_below
100	112	112
90	42	154
80	24	178
70	19	197
60	27	224
50	22	246
40	31	277
30	22	299
20	12	311
10	3	314

Sim
#hit_pct_cov_bin	count_in_bin	>bin_below
100	71	71
90	28	99
80	27	126
70	26	152
60	25	177
50	19	196
40	20	216
30	19	235
20	11	246
10	6	252

#GENERAL STATS
export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/TrinityStats.pl Trinity_Similis.fasta
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	158159
Total trinity transcripts:	314334
Percent GC: 35.51

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 6346
	Contig N20: 4502
	Contig N30: 3436
	Contig N40: 2694
	Contig N50: 2096

	Median contig length: 496
	Average contig: 1058.19
	Total assembled bases: 332626520


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 5461
	Contig N20: 3618
	Contig N30: 2621
	Contig N40: 1900
	Contig N50: 1317

	Median contig length: 357
	Average contig: 730.24
	Total assembled bases: 115494084
	
$TRINITY_HOME/util/TrinityStats.pl Trinity_Solidissima.fasta
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	118827
Total trinity transcripts:	183124
Percent GC: 35.48

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 6394
	Contig N20: 4462
	Contig N30: 3362
	Contig N40: 2628
	Contig N50: 2031

	Median contig length: 450
	Average contig: 1002.18
	Total assembled bases: 183523677


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 5030
	Contig N20: 3287
	Contig N30: 2369
	Contig N40: 1706
	Contig N50: 1188

	Median contig length: 348
	Average contig: 693.72
	Total assembled bases: 82433181



#TRANS DECODER
/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs -t Trinity_Solidissima.fasta >& log_trasdecoder_basic_Solp1.log &&
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Trinity_Solidissima.fasta >& log_trasdecoder_basic_Solp2.log &

/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs -t Trinity_Similis.fasta >& log_trasdecoder_basic_Simp1.log &&
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Trinity_Similis.fasta >& log_trasdecoder_basic_Simp2.log &

#Try this after first step
#/programs/hmmer/bin/hmmscan --cpu 2 --domtblout pfam.domtblout /workdir/hh693/P-fam-A.hmm ./Trinity_Solidissima.fasta.transdecoder_dir/longest_orfs.pep >& log_hmmscan_test.log &
#PfamA is empty


#CONVERT TO FASTA
bedtools getfasta -fi Trinity_Solidissima.fasta -bed Trinity_Solidissima.fasta.transdecoder.bed -fo Transd_Solidissima.fasta
bedtools getfasta -fi Trinity_Similis.fasta -bed Trinity_Similis.fasta.transdecoder.bed -fo Transd_Similis.fasta




#REPEAT QC WITH ISOFORM TRIMMED
export BUSCO_CONFIG_FILE=/workdir/hh693/config.ini 
export PYTHONPATH=/programs/busco-3.1.0/lib/python3.6/site-packages 
export PATH=/programs/busco-3.1.0/scripts:$PATH 
run_BUSCO.py --in ./Trinity_iso_Sol.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOiso_Solidissima -f >& BUSCO_iso_sol.log &
blastx -query ./Trinity_iso_Sol.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sol_iso.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &

generate_plot.py -wd run_BUSCOiso_Solidissima

export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol_iso.outfmt6 Trinity_iso_Sol.fasta db_ref/uniprot_sprot.fasta

#hit_pct_cov_bin	count_in_bin	>bin_below
100	12	12
90	10	22
80	5	27
70	3	30
60	3	33
50	8	41
40	5	46
30	8	54
20	5	59
10	3	62

$TRINITY_HOME/util/TrinityStats.pl Trinity_iso_Sol.fasta

################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	118827
Total trinity transcripts:	118827
Percent GC: 35.49

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 5030
	Contig N20: 3287
	Contig N30: 2369
	Contig N40: 1706
	Contig N50: 1188

	Median contig length: 348
	Average contig: 693.72
	Total assembled bases: 82433181


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 5030
	Contig N20: 3287
	Contig N30: 2369
	Contig N40: 1706
	Contig N50: 1188

	Median contig length: 348
	Average contig: 693.72
	Total assembled bases: 82433181




#REPEAT TRINITY QC WITH TRIMMED
run_BUSCO.py --in ./Transd_Solidissima.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOtransd_Solidissima -f >& BUSCO_td_sol.log &
run_BUSCO.py --in ./Transd_Similis.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOtransd_Similis -f >& BUSCO_td_sim.log &

generate_plot.py -wd run_BUSCOtransd_Solidissima
generate_plot.py -wd run_BUSCOtransd_Similis

blastx -query ./Transd_Solidissima.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sol_td.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &
blastx -query ./Transd_Similis.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sim_td.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &

export TRINITY_HOME=/programs/trinityrnaseq-v2.8.6
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sol_td.outfmt6 Transd_Solidissima.fasta db_ref/uniprot_sprot.fasta
#hit_pct_cov_bin	count_in_bin	>bin_below
100	119	119
90	67	186
80	47	233
70	28	261
60	29	290
50	49	339
40	37	376
30	49	425
20	44	469
10	15	484
$TRINITY_HOME/util/analyze_blastPlus_topHit_coverage.pl blastx_Sim_td.outfmt6 Transd_Similis.fasta db_ref/uniprot_sprot.fasta
#hit_pct_cov_bin	count_in_bin	>bin_below
100	88	88
90	43	131
80	26	157
70	26	183
60	27	210
50	20	230
40	29	259
30	23	282
20	18	300
10	12	312


$TRINITY_HOME/util/TrinityStats.pl Transd_Similis.fasta
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	24473
Total trinity transcripts:	77629
Percent GC: 37.43

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 8610
	Contig N20: 6511
	Contig N30: 5285
	Contig N40: 4381
	Contig N50: 3696

	Median contig length: 2105
	Average contig: 2653.41
	Total assembled bases: 205981945


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 7655
	Contig N20: 5748
	Contig N30: 4600
	Contig N40: 3782
	Contig N50: 3143

	Median contig length: 1520
	Average contig: 2065.15
	Total assembled bases: 50540487
	
$TRINITY_HOME/util/TrinityStats.pl Transd_Solidissima.fasta
################################
## Counts of transcripts, etc.
################################
Total trinity 'genes':	22792
Total trinity transcripts:	47988
Percent GC: 37.45

########################################
Stats based on ALL transcript contigs:
########################################

	Contig N10: 8493
	Contig N20: 6423
	Contig N30: 5170
	Contig N40: 4275
	Contig N50: 3522

	Median contig length: 1765
	Average contig: 2354.96
	Total assembled bases: 113009595


#####################################################
## Stats based on ONLY LONGEST ISOFORM per 'GENE':
#####################################################

	Contig N10: 7033
	Contig N20: 5137
	Contig N30: 4016
	Contig N40: 3249
	Contig N50: 2670

	Median contig length: 1060.5
	Average contig: 1658.61
	Total assembled bases: 37802948









SAMPLES=(
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)

#IGNORED INPUT
for ACC in "${SAMPLES[@]}"; do
	echo "$ACC"
	nohup bwa mem -t 18  -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA ${ACC}_R1.fastq.gz ${ACC}_R2.fastq.gz | samtools view -Sb -@18 -o ${ACC}_iso_output.bam -
done


#MARK DUPLICATES
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

ACC=Sim4
SAM=Solidissima
REFFASTA=Sol_ref.fa

gatk MarkDuplicatesSpark \
-I ${ACC}_iso_output.bam \
-O ${ACC}.sorted.dedup.bam \
-M ${ACC}.sorted.dedup.txt \
--tmp-dir $TMP \
--conf "spark.executor.cores=8" \
>& sortdedup_${ACC}.log &





#HAPLOTYPE CALLER





#gatk MarkDuplicatesSpark -I Sim4_iso_output.bam -O Sim4_iso.sorted.dedup.bam -M Sim4_iso.sorted.dedup.txt >& sortdedup_Sim4.log &
	#WARNING: An illegal reflective access operation has occurred
	#WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/programs/gatk-4.1.4.0/gatk-package-4.1.4.0-local.jar) to method java.nio.Bits.unaligned()
	#WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
	#WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
	#WARNING: All illegal access operations will be denied in a future release

${ACC}_iso_output.bam

ACC=Sim4

gatk --java-options "-Xmx4g"  HaplotypeCaller \
    --tmp-dir $TMP \
     -R $REFFASTA \
     -I ${ACC}_iso_output.bam  \
     -ERC GVCF \
     --native-pair-hmm-threads 10 \
     --minimum-mapping-quality 30 \
     -O $ACC.g.vcf >& hc_$ACC.log &

gatk --java-options "-Xmx4g"  HaplotypeCaller \
     --tmp-dir $TMP \
     -R $REFFASTA \
     -I $ACC_iso_output.bam   \
     -ERC GVCF \
     --native-pair-hmm-threads 10 \
     --minimum-mapping-quality 30 \
     -O $ACC.g.vcf >& hc_$ACC.log &




#Struggling downline from bwa align. The output is incompatible with GATK
#Trying lots of different things (see below)

#Jun 19th, trying to run the code from the workshop



#PERL SCRIPT
chmod u+x extract_longest_from_trinity.sh
./extract_longest_from_trinity.sh trinity_out_Solidissima/Trinity.fasta > ./Trinity_Sol_longest.fasta
#Output was 296K, Input was 190M, very quick <2 min
./extract_longest_from_trinity.sh trinity_out_Similis/Trinity.fasta > ./Trinity_Sim_longest.fasta
#Output was 277K, Input was 349M, also quick
# wc -l Trinity_Sim_longest.fasta 
# 3513 Trinity_Sim_longest.fasta
# wc -l trinity_out_Similis/Trinity.fasta
# 628668 trinity_out_Similis/Trinity.fasta


#TRANS DECODER
/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs -t Trinity_Solidissima.fasta >& log_trasdecoder_basic_Solp1.log &&
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Trinity_Solidissima.fasta >& log_trasdecoder_basic_Solp2.log &

/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs -t Trinity_Similis.fasta >& log_trasdecoder_basic_Simp1.log &&
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Trinity_Similis.fasta >& log_trasdecoder_basic_Simp2.log &

#Try this after first step
#/programs/hmmer/bin/hmmscan --cpu 2 --domtblout pfam.domtblout /workdir/hh693/P-fam-A.hmm ./Trinity_Solidissima.fasta.transdecoder_dir/longest_orfs.pep >& log_hmmscan_test.log &
#PfamA is empty

#REPEAT TRINITY QC WITH TRIMMED
run_BUSCO.py --in ./Transd_Solidissima.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOtransd_Solidissima -f >& BUSCO_td_sol.log &
run_BUSCO.py --in ./Transd_Similis.fasta --lineage_path ./db_ref/metazoa_odb10 --mode transcriptome --cpu 8 --out BUSCOtransd_Similis -f >& BUSCO_td_sim.log &

generate_plot.py -wd run_BUSCOtransd_Solidissima
generate_plot.py -wd run_BUSCOtransd_Similis

blastx -query ./Transd_Solidissima.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sol_td.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &
blastx -query ./Transd_Similis.fasta -db ./db_ref/uniprot_sprot.fasta -out blastx_Sim_td.outfmt6 -evalue 1e-20 -num_threads 4 -max_target_seqs 1 -outfmt 6 &


#CONVERT TO FASTA
bedtools getfasta -fi Trinity_Solidissima.fasta -bed Trinity_Solidissima.fasta.transdecoder.bed -fo Transd_Solidissima.fasta
bedtools getfasta -fi Trinity_Similis.fasta -bed Trinity_Similis.fasta.transdecoder.bed -fo Transd_Similis.fasta



#BWA ALIGN
nohup ./HGH_bwa_aln.sh >& bwa_aln_all.log &

#Basic script code:
ACC=Sol6
SAM=Solidissima
REFFASTA=Sol_ref.fa

bwa mem -M -t 22 \
 -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 ${ACC}_clean_R1.fastq.gz  ${ACC}_clean_R2.fastq.gz \
 | samtools view -Sb - > $ACC_s.bam
 
ACC=Sol8...

#Should take less than 400 CPU minutes per sample
#FOR LOOP NOT WORKING, DO IT INDIVIDUALLY AS A SCRIPT
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
SAM=Solidissima
REFFASTA=Sol_ref.fa
for ACC in "${SAMPLES[@]}"; do
	echo "$ACC"
	bwa mem -M -t 14 \
 		-R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 		${ACC}_clean_R1.fastq.gz  ${ACC}_clean_R2.fastq.gz \
 		| samtools view -Sb - > $ACC_t.bam >& bwa_aln_${ACC}_t.log
done
#PASTE IN ONE LINE AT A TIME (or maybe with no identations)
#_t stands for testing the for loop and doing them all at once. Sol6.bam and Sol6_t.bam should be identical
# no & at the end so it does not run them in parallel 

#Finished .bam files are about 5G
#Trying again on 7 threads because that's the main thing I changed between then and now,
#If that fails again, try doing it not in a script.
#Also possible that I did it in the past without .gz (yes), but looks like workshop did it with .gz but only 4 threads
#Maybe going too fast over two threads is causing it to duplicate headers
#gunzip -c maintains .gz file too


#Running bwa with 7 threads = _s.bam over night
nohup ./HGH_bwa_aln_s.sh >& bwa_aln_s.log &

#Did not save? or something, looked like it never made the .bam file.
#Now trying bwa_r which stands for raw. These raw reads were uncut by trimmomatic
#Compare how Sim6_R1 looks compared to Sim6_clean_R1
#They look the same to me...

#STILL NOT SAVING THE BAM FILES SOMETHING IS GOING WRONG


[[ $Sim6_R1.fastq.gz == $Sim6_clean_R1.fastq.gz ]] && echo yes
yes

#YUP
#its almost like the processes are getting interrupted when my computer disconnects from the server
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
SAM=Solidissima
REFFASTA=Sol_ref.fa
for ACC in "${SAMPLES[@]}"; do
echo "$ACC"
bwa mem -M -t 7 \
-R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
${ACC}_R1.fastq.gz  ${ACC}_R2.fastq.gz \
| samtools view -Sb - > $ACC_r.bam
done

#With  >& bwa_aln_${ACC}_r.log   it kept not saving anything


SAMPLESB=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)
for ACCB in "${SAMPLESB[@]}"; do
gunzip -c ${ACCB}_clean_R1.fastq.gz > ${ACCB}_clean_R1.fastq
gunzip -c ${ACCB}_clean_R2.fastq.gz > ${ACCB}_clean_R2.fastq
done


#BWA INDEX
#MARK DUPLICATES AND HAPLOTYPE CALLER : CREATE SCRIPT
#INITIALIZE JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
#RUN INDEX
REFFASTA=./Sol_ref.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH

nohup ./HGH_sortdup_GATK.sh >& sort_GATK_all.log &
#DID NOT WORK

#It appears something in transdecoder is incompatible with 
#Nope, its the .bam file's fault.


A USER ERROR has occurred: Failed to read bam header from Sol6.bam
 Caused by:Cannot add sequence that already exists in SAMSequenceDictionary

#Try converting to .sam so I can remove bad headers
samtools view -h Sim6.bam > Sim6.sam &
samtools view -h Sim6.bam | less #You can view without converting to sam


#BWA INDEX
#INITIALIZE JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
#RUN INDEX
REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
#DOES NOT WORK IN SCRIPT FOR SOME REASON
gatk MarkDuplicatesSpark \
            -I Sim4.bam \
            -O Sim4.sorted.dedup.bam \
            -M Sim4.sorted.dedup.txt >& sdedupi_Sim4.log &
#TAKES ABOUT 40 MINUTES WHEN 1 AT A TIME

#HAPLOTYPE CALLER
#HAPLOTYPE CALLER WITH GATK
#SET WITHIN FUNCTION OR IT IGNORES INPUT
#HAPLOTYPE CALL INDIVIDUALLY
#INITIALIZE JAVA
export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
#TMP=/workdir/$USER/TrimmedSeq/tmp
export PATH=$GATKDIR:$PATH
ACC=Sol
#mkdir tmpgatk$ACC

gatk --java-options "-Xmx4g"  HaplotypeCaller \
    --tmp-dir tmpgatk$ACC \
     -R $REFFASTA \
     -I $ACC.sorted.dedup.bam  \
     -ERC GVCF \
     --native-pair-hmm-threads 10 \
     --minimum-mapping-quality 30 \
     -O $ACC.g.vcf >& hc_$ACC.log &


#COMBINE GVCF




#FILTERING





#1/1 AND 0/0 NO 0/1
#PHASING IS THE SAME





#Excluding homology searching (IF it reduces total, if it increases include), predict ORFs

gunzip Pfam-A.hmm.gz
cp /shared_data/genome_db/BLAST_NCBI/swissprot* ./

#Try this after first step
hmmscan --cpu 8 --domtblout pfam.domtblout /path/to/Pfam-A.hmm transdecoder_dir/longest_orfs.pep



#THEN GO TO: https://github.com/TransDecoder/TransDecoder/wiki and download Pfam and upload with Filezilla
#gunzip Pfam-A.hmm.gz
#/programs/hmmer/bin/hmmconvert Pfam-A.hmm  >  ./Pfam/Pfam-A.hmm
#/programs/hmmer/bin/hmmpress ./Pfam/Pfam-A.hmm
#/programs/hmmer/bin/hmmscan --cpu 16 --domtblout pfam.domtblout ./Pfam/Pfam-A.hmm Solidis_Trinity.fasta.transdecoder_dir/longest_orfs.pep 
#/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Solidis_Trinity.fasta --retain_pfam_hits pfam.domtblout
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Solidis_Trinity.fasta
#EVERYTHING BUT HMM RUNS ON ONLY 100% CPU


#BBMAP NOTES

#BACKGROUND: EXTRA TRIM WITH HISTOGRAMS
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)

export PATH=/programs/bbmap-38.73:$PATH

for SAMPLE in "${SAMPLES[@]}"; do
	echo "$SAMPLE"
	bbduk.sh in1=$SAMPLE'_R1.fastq.gz' in2=$SAMPLE'_R2.fastq.gz' out1=$SAMPLE'_clean_Ex_R1.fastq.gz' out2=$SAMPLE'_clean_Ex_R2.fastq.gz' ref=/programs/bbmap-38.73/resources/adapters.fa maq=10 qtrim=r trimq=10 minlen=50 bhist=$SAMPLE'bhist.txt' qhist=$SAMPLE'qhist.txt' gchist=$SAMPLE'gchist.txt' aqhist=$SAMPLE'aqhist.txt' lhist=$SAMPLE'lhist.txt' gcbins=auto ktrim=r k=23 mink=11 hdist=1 tpe tbo >& $SAMPLE'_Extra_bbmap.log'
done




Ktrim is adapter trimming


(if your data is very low quality, you may wish to use more sensitive settings of hdist=2 k=21)
quality trimming: bbduk.sh in=reads.fq out=clean.fq qtrim=r trimq=10

quality filtering: bbduk.sh in=reads.fq out=clean.fq maq=10
This will discard reads with average quality below 10. If quality-trimming is enabled, the average quality will be calculated on the trimmed read.

Length filtering:
bbduk.sh in=reads.fq out=clean.fq qtrim=r trimq=10 minlen=100
This will discard reads shorter than 100bp after trimming to Q10. Alternatively, using “mlf=50” (minlengthfraction=50) would discard reads under 50% of their original length after trimming. Either of these flags apply to any trim operation, whether force-trim (ftr, ftl, ftm), quality-trimming (qtrim), or kmer-trimming (ktrim). “mlf” compares the final length after all trim operations to the initial length before any trim operations.

Histogram generation:
bbduk.sh in=reads.fq bhist=bhist.txt qhist=qhist.txt gchist=gchist.txt aqhist=aqhist.txt lhist=lhist.txt gcbins=auto
This will generate histograms of various aspects of the reads – base frequency, quality scores, gc content, average quality, and length. BBMap can generate even more histograms by using mapping information (such as quality accuracy and indel length); BBDuk can also generate these histograms if it is fed a sam file in which the cigar strings use = and X to denote match and mismatch.

Therkildsen: Trimmomatic sliding window approach to trim off the
rest of the read if the average sequence quality over any
four bases fell below 15


#Date: June 3 2020
#TRIMMOMATIC
SAMPLES=(
    Sim4
    Sim5
    Sim6
    Sol10
    Sol8
    Sol7
    Sol6
)

for SAMPLE in "${SAMPLES[@]}"; do
    echo "$SAMPLE"
    java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 22 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3 MINLEN:30
done


#Trimmed nothing:
#LEADING TRAILING, NO MINLEN
for SAMPLE in "${SAMPLES[@]}"; do
    echo "$SAMPLE"
    java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3
done

#MINLEN:80				trim everything
    java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3 MINLEN:80
#MINIMAL PARAMETERS		keep everything
	java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10
#MINLEN:50				keep everthing
	 java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3 MINLEN:50



java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3 MINLEN:50
#TRY THE OTHER ONES
NexteraPE-PE.fa  TruSeq2-PE.fa  TruSeq2-SE.fa  TruSeq3-PE-2.fa  TruSeq3-PE.fa  TruSeq3-SE.fa

#TRUSEQ2
Input Read Pairs: 103618581 Both Surviving: 103578940 (99.96%) Forward Only Surviving: 39530 (0.04%) Reverse Only Surviving: 63 (0.00%) Dropped: 48 (0.00%)
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq2-PE.fa:2:30:10

#TRUSEQ3-2
Input Read Pairs: 43052885 Both Surviving: 43038007 (99.97%) Forward Only Surviving: 13625 (0.03%) Reverse Only Surviving: 1248 (0.00%) Dropped: 5 (0.00%)
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-PE-2.fa:2:30:10

#TRUSEQ3
Input Read Pairs: 103618581 Both Surviving: 103566192 (99.95%) Forward Only Surviving: 52383 (0.05%) Reverse Only Surviving: 0 (0.00%) Dropped: 6 (0.00%)
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-PE.fa:2:30:10


#NO ILLUMINACLIP
kept all
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq'  LEADING:3 TRAILING:3 MINLEN:30


#SEQUENCE LENGTH = 76





#NO NUMBERS AFTER ADAPTORS (DOES NOT RUN)



#Sol8
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_Trim_1P.fastq' $SAMPLE'_Trim_1U.fastq' $SAMPLE'_Trim_2P.fastq' $SAMPLE'_Trim_2U.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10:2:true LEADING:3 TRAILING:3 MINLEN:80


echo $SAMPLE'_R1.fastq.gz'




#PREPARE
mkdir /workdir/hh693
cd /workdir/hh693
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sol*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sim*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*ref* . &
cp /programs/trimmomatic/adapters/NexteraPE-PE.fa . &

SAMPLELIST=(Sol8)

#TRIMMOMATIC
for SAMPLE in ${SAMPLELIST[@]} 
do
echo $SAMPLE
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_AdapterClipped_F_paired.fastq' $SAMPLE'_AdapterClipped_F_unpaired.fastq' $SAMPLE'_AdapterClipped_R_paired.fastq' $SAMPLE'_AdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10
done
#REMOVED FRONT END ADAPTERS ON MOST
Input Read Pairs: 43052885 Both Surviving: 43052759 (100.00%) Forward Only Surviving: 126 (0.00%) Reverse Only Surviving: 0 (0.00%) Dropped: 0 (0.00%)
#NOT WORKING ON A LATER DATE


#TRANSDECODER
/programs/TransDecoder-v5.5.0/TransDecoder.LongOrfs -t Solidis_Trinity.fasta
cp /shared_data/genome_db/BLAST_NCBI/swissprot* ./
#THEN GO TO: https://github.com/TransDecoder/TransDecoder/wiki and download Pfam and upload with Filezilla
#gunzip Pfam-A.hmm.gz
#/programs/hmmer/bin/hmmconvert Pfam-A.hmm  >  ./Pfam/Pfam-A.hmm
#/programs/hmmer/bin/hmmpress ./Pfam/Pfam-A.hmm
#/programs/hmmer/bin/hmmscan --cpu 16 --domtblout pfam.domtblout ./Pfam/Pfam-A.hmm Solidis_Trinity.fasta.transdecoder_dir/longest_orfs.pep 
#/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Solidis_Trinity.fasta --retain_pfam_hits pfam.domtblout
/programs/TransDecoder-v5.5.0/TransDecoder.Predict -t Solidis_Trinity.fasta
#EVERYTHING BUT HMM RUNS ON ONLY 100% CPU

#BWA PREPARE REF
#Needed for later gatk steps
#Set program path
TMP=/workdir/$USER/tmp
GATKDIR=/programs/gatk-4.1.4.0
export PATH=$GATKDIR:$PATH
gatk CreateSequenceDictionary -R Sol_trim_ref.fa  -O Sol_trim_ref.dict
samtools faidx Sol_trim_ref.fa
#Index for BWA alignment
bwa index Sol_trim_ref.fa

#RENAME FILES
#Did manually (i.e. messy), see below to copy most
#Next time make the trim output already .gz (andor named well)
#chmod u=rwx,g=rx,o=r HGH_bwa_aln_NoPf.sh

#NUMERICAL NOTES
#Without Pfam Ref.fa > 216M to 78M
#However, it does look like everything else scaled off that
#I'm just worried that the headers in the .vcf for position will look insane.

#Previously the .bam for all Sim and all Sol together were each about 30 G
#Right now, about 18 min in to the first one it is at about 3G, so if each is ~10
#Then each will take an hour, I have 7 of them.
#Check previous time for bwa algn to complete: 

-rw-rw-r--  1 hh693 hh693 6.5M May 27 00:16 Sol_trim_ref_NoPf.dict
-rw-rw-r--  1 hh693 hh693  78M May 27 00:13 Sol_trim_ref_NoPf.fa
-rw-rw-r--  1 hh693 hh693   17 May 27 00:18 Sol_trim_ref_NoPf.fa.amb
-rw-rw-r--  1 hh693 hh693 8.9M May 27 00:18 Sol_trim_ref_NoPf.fa.ann
-rw-rw-r--  1 hh693 hh693  69M May 27 00:18 Sol_trim_ref_NoPf.fa.bwt
-rw-rw-r--  1 hh693 hh693 2.4M May 27 00:16 Sol_trim_ref_NoPf.fa.fai
-rw-rw-r--  1 hh693 hh693  18M May 27 00:18 Sol_trim_ref_NoPf.fa.pac


-rw-rw-r--  1 hh693 hh693  21M May 26 23:09 Solidis_ref.dict
-rw-rw-r--  1 hh693 hh693 216M May 26 23:09 Solidis_ref.fa
-rw-rw-r--  1 hh693 hh693   19 May 26 23:09 Solidis_ref.fa.amb
-rw-rw-r--  1 hh693 hh693  18M May 26 23:09 Solidis_ref.fa.ann
-rw-rw-r--  1 hh693 hh693 201M May 26 23:09 Solidis_ref.fa.bwt
-rw-rw-r--  1 hh693 hh693 8.1M May 26 23:09 Solidis_ref.fa.fai
-rw-r--r--  1 hh693 hh693 372M May 26 23:09 Solidis_ref.fa.img
-rw-rw-r--  1 hh693 hh693  51M May 26 23:09 Solidis_ref.fa.pac
-rw-rw-r--  1 hh693 hh693 101M May 26 23:09 Solidis_ref.fa.sa


grep "1/1" Sol7.test.vcf | wc -l
19324
grep "0/1" Sol7.test.vcf | wc -l
27334
grep "0/0" Sol7.test.vcf | wc -l
1463913
grep "0|0" Sol7.test.vcf | wc -l
2120
grep "1|1" Sol7.test.vcf | wc -l
17832




REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
mkdir tmpcombTEST
export PATH=$GATKDIR:$PATH
gatk CombineGVCFs --tmp-dir tmpcombTEST -R $REFFASTA --variant Sol8.g.vcf --variant Sol10.g.vcf -O alltest.g.vcf 


export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH


cp -r /programs/spark-2.2.1-bin-hadoop2.7  /workdir/spark


export JAVA_HOME=/usr/local/jdk1.8.0_121
export PATH=$JAVA_HOME/bin:$PATH
REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
mkdir tmpSol10b
export PATH=$GATKDIR:$PATH
ACC=Sol10
#mkdir tmpgatk$ACC

gatk --java-options "-Xmx4g"  HaplotypeCaller \
    --tmp-dir tmpSol10b \
     -R $REFFASTA \
     -I $ACC.sorted.dedup.bam  \
     -ERC GVCF \
     --native-pair-hmm-threads 10 \
     --minimum-mapping-quality 30 \
     -O $ACC.g.vcf >& hc_$ACC.log &


REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
gatk MarkDuplicatesSpark -I Sim4.bam -O Sim4.sorted.dedup.bam -M Sim4.sorted.dedup.txt >& sdedupi_Sim4.log && 
gatk MarkDuplicatesSpark -I Sim5.bam -O Sim5.sorted.dedup.bam -M Sim5.sorted.dedup.txt >& sdedupi_Sim5.log & 
gatk MarkDuplicatesSpark -I Sim6.bam -O Sim6.sorted.dedup.bam -M Sim6.sorted.dedup.txt >& sdedupi_Sim6.log 
echo "done (probably)"


gatk MarkDuplicatesSpark \
            -I Sol10.bam \
            -O Sol10.sorted.dedup.bam \
            -M Sol10.sorted.dedup.txt >& sdedupi_Sol10.log &

Sol10 did not have index
REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
#DOES NOT WORK IN SCRIPT FOR SOME REASON
gatk MarkDuplicatesSpark \
            -I Sol6.bam \
            -O Sol6.sorted.dedup.bam \
            -M Sol6.sorted.dedup.txt >& sdedupi_Sol6.log &




REFFASTA=./Sol_trim_ref_NoPf.fa
GATKDIR=/programs/gatk-4.1.4.0
TMP=/workdir/$USER/tmp
export PATH=$GATKDIR:$PATH
#DOES NOT WORK IN SCRIPT FOR SOME REASON
gatk MarkDuplicatesSpark \
            -I Sol6.bam \
            -O Sol6.sorted.dedup.bam \
            -M Sol6.sorted.dedup.txt >& sdedupi_Sol6.log &


gatk MarkDuplicatesSpark \
            -I ${ACC}.bam \
            -O ${ACC}.sorted.dedup.bam \
            -M ${ACC}.sorted.dedup.txt \
            --tmp-dir $TMP \ 					<- ?
            --conf 'spark.executor.cores=8'     <- ?
            
gatk MarkDuplicatesSpark \
 	-I Sim.bam \ 
	-O Sim.sorted.dedup.bam \ 
	-M Sim.sorted.dedup.metrics.txt &


#Set ACC within .sh
#nohup ./HGH_bwa_aln.sh >& ./logs/bwa_aln_Sol6.log &
#Ran manually, not script cause it said "ignored input"

ACC=Sol6
SAM=Solidissima
REFFASTA=Sol_trim_ref_NoPf.fa

bwa mem -M -t 7 \
 -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 ${ACC}_R1.fastq  ${ACC}_R2.fastq \
 | samtools view -Sb - > $ACC.bam &



bwa mem -M -t 7 \
 -R "@RG\tID:Sol8\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 Sol8_R1.fastq  Sol8_R2.fastq \
 | samtools view -Sb - > Sol8.bam &

bwa mem -M -t 7 \
 -R "@RG\tID:Sol10\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 Sol10_R1.fastq  Sol10_R2.fastq \
 | samtools view -Sb - > Sol10.bam &

#Looks like it is working, but log is not being saved 
#Try next time to do >& bwa_align_$ACC.log


bwa mem -M -t 7 \
 -R "@RG\tID:Sim4\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 Sim4_R1.fastq.gz  Sim4_R2.fastq.gz \
 | samtools view -Sb - > Sim4.bam &

bwa mem -M -t 7 \
 -R "@RG\tID:Sim6\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 Sim6_R1.fastq  Sim6_R2.fastq \
 | samtools view -Sb - > Sim6.bam &


bwa mem -M -t 7 \
 -R "@RG\tID:Sim5\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 Sim5_R1.fastq  Sim5_R2.fastq \
 | samtools view -Sb - > Sim5.bam

cd TrimmedSeq
cp * ../
gzip *fastq*
#GZIP KEEPS ORIGINAL TOO







[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sim5g_ATTACTCG_GCCTCTAT_AdapterClipped_R_paired.fastq Sim5_R2.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sim6g_ATTACTCG_AGGATAGG_AdapterClipped_F_paired.fastq Sim6_R1.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sim6g_ATTACTCG_AGGATAGG_AdapterClipped_R_paired.fastq Sim6_R2.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_AdapterClipped_F_paired.fastq Sol10_R1.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_AdapterClipped_R_paired.fastq Sol10_R2.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol6g_ATTACTCG_TCAGAGCC_AdapterClipped_F_paired.fastq Sol6_R1.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol6g_ATTACTCG_TCAGAGCC_AdapterClipped_R_paired.fastq Sol6_R2.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol7g_ATTACTCG_CTTCGCCT_AdapterClipped_F_paired.fastq Sol7_R1.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol7g_ATTACTCG_CTTCGCCT_AdapterClipped_R_paired.fastq Sol7_R2.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol8g_ATTACTCG_TAAGATTA_AdapterClipped_F_paired.fastq Sol8_R1.fastq
[hh693@cbsumm06 TrimmedSeq]$ mv 10975_5776_103466_HVGNYBGXB_10418659_Sol8g_ATTACTCG_TAAGATTA_AdapterClipped_R_paired.fastq Sol8_R2.fastq


gatk CreateSequenceDictionary -R Sol_trim_ref_NoPf.fa  -O Sol_trim_ref_NoPf.dict
samtools faidx Sol_trim_ref.fa
#Index for BWA alignment
bwa index Sol_trim_ref.fa





#Use hmmpress first?
/programs/hmmer/bin/hmmconvert Pfam-A.hmm  >  ./Pfam/Pfam-A.hmm

/programs/hmmer/bin/hmmscan --cpu 16 --domtblout pfam.domtblout ./Pfam-A.hmm Solidis_Trinity.fasta.transdecoder_dir/longest_orfs.pep 



/programs/hmmer/bin/hmmscan

#After 50 minutes of running hmmscan: it is on DN481/DN78000 = 0.6% but also it'a jumping around so I'm not so sure about that



wget ftp://ftp.sanger.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz
cp /shared_data/genome_db/BLAST_NCBI/swissprot* ./

hmmscan --cpu 16 --domtblout pfam.domtblout /path/to/Pfam-A.hmm transdecoder_dir/longest_orfs.pep


#INDEX OUT OF BOUNDS: java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 8 -phred33 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_AdapterClipped_F_paired.fastq' $SAMPLE'_AdapterClipped_F_unpaired.fastq' $SAMPLE'_AdapterClipped_R_paired.fastq' $SAMPLE'_AdapterClipped_R_unpaired.fastq' ILLUMINACLIP:NexteraPE-PE.fa MINLEN:80

#WITH ANY LEVEL OF MIN LENGTH, IT DROPS ALL READS 
#MINLENGTH 2 KEPT ALL 
#WORKING BETTER LATER UP TO 40 (80 STILL DID NOT WORK)


mkdir TrimmedSeq
mv *_Ad*_paired* ./TrimmedSeq
mv *unpaired* ./Unpaired





SAMPLE='10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG'
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R1.fastq.gz 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R2.fastq.gz $SAMPLE'_MINAdapterClipped_F_paired.fastq' $SAMPLE'_MINAdapterClipped_F_unpaired.fastq' $SAMPLE'_MINAdapterClipped_R_paired.fastq' $SAMPLE'_MINAdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10 MINLEN:20

java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R1.fastq.gz 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R2.fastq.gz $SAMPLE'_MINAdapterClipped_F_paired.fastq' $SAMPLE'_MINAdapterClipped_F_unpaired.fastq' $SAMPLE'_MINAdapterClipped_R_paired.fastq' $SAMPLE'_MINAdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10 MINLEN:40

for $SAMPLE in ${test_array[@]} ; do echo $SAMPLE; done

for SOL in ${SAMPLELISTSOL[@]} 
do
echo $SAMPLE
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SOL'_R1.fastq.gz' $SOL'_R2.fastq.gz' $SOL'_AdapterClipped_F_paired.fastq' $SOL'_AdapterClipped_F_unpaired.fastq' $SOL'_AdapterClipped_R_paired.fastq' $SOL'_AdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10 
done


for SAMPLE in ${SAMPLELIST[@]} 
do
echo $SAMPLE
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 10 $SAMPLE'_R1.fastq.gz' $SAMPLE'_R2.fastq.gz' $SAMPLE'_AdapterClipped_F_paired.fastq' $SAMPLE'_AdapterClipped_F_unpaired.fastq' $SAMPLE'_AdapterClipped_R_paired.fastq' $SAMPLE'_AdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10
done



#PREPARE
cd /workdir/hh693
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sol*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sim*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*ref* .&
cp /programs/trimmomatic/adapters/NexteraPE-PE.fa . &
nohup ./HGH_Trimmomatic.sh SimSampleList.txt TrimmedSeq >& TrimmomaticSimPhed0518.log &


nohup ./HGH_Trimmomatic.sh SolSampleList.txt TrimmedSeq >& TrimmomaticSolPhed0518.log &





##Trimmommatic

#!/bin/bash

# A subset of the commands used in the pipeline described in Therkildsen and Palumbi: "Practical low-coverage genome-wide sequencing of hundreds of individually barcoded samples for population and evolutionary genomics in non-model species" published in Molecular Ecology Resources.
# usage: nohup ./Trimmomatic_mph.sh SAMPLELIST OUTPUTDIR >& NYC_trimmomatic.log &

SAMPLELIST=$1 # Filename and path to list of fastq file base names (remove _R1.fastq.gz) e.g. /workdir/mphwork/NYC_WGS_samples.txt
OUTPUTDIR=$2 # path to directory where output files are to be written, e.g. /workdir/mphwork/trimmed
##ADAPTERS=$3 # /workdir/Cod/ReferenceSeqs/NexteraPE_NT.fa is a list of adapter/index sequences for Nextera DNA and Nextera XT PE libraries

##### RUN EACH SAMPLE THROUGH PIPELINE #######
# Loop over each sample
for SAMPLEFILE in `cat $SAMPLELIST | cut -f1`; do
SAMPLE=`grep "$SAMPLEFILE" $SAMPLELIST | cut -d "_" -f9-10`
SAMPLE=$OUTPUTDIR$SAMPLE'_1'

#### CLEANING THE READS ####
# Remove adapter sequence with Trimmomatic, minlength=80. 
java -jar /programs/trimmomatic/trimmomatic-0.36.jar PE -threads 22 -phred33 $SAMPLEFILE'_R1.fastq.gz' $SAMPLEFILE'_R2.fastq.gz' $SAMPLE'_AdapterClipped_F_paired.fastq' $SAMPLE'_AdapterClipped_F_unpaired.fastq' $SAMPLE'_AdapterClipped_R_paired.fastq' $SAMPLE'_AdapterClipped_R_unpaired.fastq' ILLUMINACLIP:/programs/trimmomatic/adapters/NexteraPE-PE.fa:2:30:10 MINLEN:80
done




#Date: May 18 2020
Filter before I BWA prepare
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sol*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sim*fastq* . &


/programs/cd-hit-v4.6.8-2017-1208/cd-hit-est -o cdhit -c 0.9 -i Solidis_Filter.fasta -p 1 -d 0 -T 0 &
mv cdhit Sol_cdhit_ref.fa
./HGH_prepare_genome_GATK.sh >& prepare_genome.log &





java -jar /programs/trimmomatic/trimmomatic-0.39.jar [your_options_here]

Common adapter files are in /programs/trimmomatic/adapters. To run ILLUMINACLIP you will need to specify the path. ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-PE-2.fa:2:30:10 E.g.(you need to change the minimum kept read legth MINLEN):

Palindrome mode (cleaner, short reads with adapters are all included in unpaired_1.fastq, not in paired files):
java -jar /programs/trimmomatic/trimmomatic-0.39.jar PE -phred33 paired_end_reads_1.fastq paired_end_reads_2.fastq kept_paired_end_reads_1.fastq unpaired_1.fastq kept_paired_end_reads_2.fastq  unpaired_2.fastq ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-PE-2.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:200

Simple mode:
java -jar /programs/trimmomatic/trimmomatic-0.39.jar PE -phred33 paired_end_reads_1.fastq paired_end_reads_2.fastq kept_paired_end_reads_1.fastq unpaired_1.fastq kept_paired_end_reads_2.fastq  unpaired_2.fastq ILLUMINACLIP:/programs/trimmomatic/adapters/TruSeq3-SE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:200






# c = 0.9
# b = default

#Then do BWA prepare genome



#Filtering Transcriptome May 10th

cp /home/mph75_0001/shared/Hannah/May2020_workdir/*ref* .
cp Solidis_ref.fa ./Solidis_filtertest.fa

/programs/cd-hit-v4.6.8-2017-1208/cd-hit -h
/programs/cd-hit-v4.6.8-2017-1208/cd-hit-est -o cdhit -c 0.98 -i Solidis_filtertest.fa -p 1 -d 0 -b 3 -T 0
#WHY: CD-HIT can be used to cluster highly similar sequences and retain a single representative sequence per group. Stringent clustering can be done like so

#Code completed in about 15 minutes
#Created two files: cdhit and cdhit.clstr
#cdhit looks like the ref.fa
#cdhit.clstr is a list of which contigs go together?

wc -l Solidis_ref.fa
#355,144 Solidis_ref.fa

wc -l cdhit
# 327,990 cdhit

#Not much filtering but some.

#Set up for bam, get rid of others
mv ./*Sol* ./OldGenomes/
mv cdhit Sol_cdhit_ref.fa
 
 
#Align to Transcriptome
#Prepare transcriptome

bwa index -p Sol_cdhit_Transcriptome Sol_cdhit_ref.fa &
#Takes about 8 minutes on the 8 cpu

#Import fastq files
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sol*fastq* . &
cp /home/mph75_0001/shared/Hannah/Trials_previous_MarkerDevelopment/Mar2020_workingdir/*Sim*fastq* . &
#Takes time to copy

#Import scripts from previous work
#HGH_bwa_aln.sh
#HGH_prepare_genome_GATK.sh

chmod u=rwx,g=rx,o=r HGH_prepare_genome_GATK.sh
chmod u=rwx,g=rx,o=r HGH_bwa_aln.sh

./HGH_prepare_genome_GATK.sh >& prepare_genome.log &

#Sim 4 and Sol 10 done first, Sim5, Sol 6
#Rename for simplicity
mv 10975_5776_103466_HVGNYBGXB_10418659_Sim4g_ATTACTCG_AGGCTATA_R1.fastq.gz ./Sim4_R1.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sim4g_ATTACTCG_AGGCTATA_R2.fastq.gz ./Sim4_R2.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R1.fastq.gz ./Sol10_R1.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol10g_ATTACTCG_ACGTCCTG_R2.fastq.gz ./Sol10_R2.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sim5g_ATTACTCG_GCCTCTAT_R1.fastq.gz ./Sim5_R1.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sim5g_ATTACTCG_GCCTCTAT_R2.fastq.gz ./Sim5_R2.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol6g_ATTACTCG_TCAGAGCC_R1.fastq.gz ./Sol6_R1.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol6g_ATTACTCG_TCAGAGCC_R2.fastq.gz ./Sol6_R2.fastq.gz

#Finished processing later
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol7g_ATTACTCG_CTTCGCCT_R1.fastq.gz ./Sol7_R1.fastq.gz
mv 10975_5776_103466_HVGNYBGXB_10418659_Sol7g_ATTACTCG_CTTCGCCT_R2.fastq.gz ./Sol7_R2.fastq.gz


#First try saving as log.


#Run bwa align for one at a time
#Run in a for loop to step away:

################## FOR LOOP FOR RUNNING MULTIPLE BWA ALIGN IN A ROW ##############

#Put all ACC in one vector as strings, then run For Loop
declare -a ACCS=("Sim3" "Sol8" "Sim19")

for A in ${ACCS[@]}
do
ACKY=$A
echo $ACKY "begin"

ACC=$ACKY
SAM=Solidissima
REFFASTA=Sol_cdhit_ref.fa

bwa mem -M -t 7 \
 -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 ${ACC}_R1.fastq.gz  ${ACC}_R2.fastq.gz \
 | samtools view -Sb - > $ACC.bam >& bwa_align_$ACC.log

echo $ACKY "completed"

done








#Set ACC within .sh
#nohup ./HGH_bwa_aln.sh >& ./logs/bwa_aln_Sol6.log &
#Ran manually, not script cause it said "ignored input"

ACC=Sol6
SAM=Solidissima
REFFASTA=Sol_cdhit_ref.fa

bwa mem -M -t 7 \
 -R "@RG\tID:${ACC}\tSM:${SAM}\tLB:${SAM}\tPL:ILLUMINA" $REFFASTA \
 ${ACC}_R1.fastq.gz  ${ACC}_R2.fastq.gz \
 | samtools view -Sb - > $ACC.bam


#Looks like it is working, but log is not being saved 

#Try next time to do >& bwa_align_$ACC.log

#What do I do 






################ RUN LINES #####################
grep -v "#" Sim.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' > Sim.test.vcf
grep "1/1" Sim.test.vcf | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' > Sim.filter.vcf
grep -v "#" Sol.g.vcf > Sol.test.vcf 

export OMP_NUM_THREADS=16

/programs//R-3.5.0s/bin/R
#install.packages("tidyverse")
library("tidyverse")
Sol <- read.table("Sol.test.vcf")
Sim <- read.table("Sim.filter.vcf")
Sim["V11"] = "P"

for (i in 1:nrow(Sol)) {
chrom <- Sol[i,1]
pos <- Sol[i,2]
for (j in 1:nrow(Sim)) {
if (Sim[j,1]==chrom & Sim[j,2]==pos) {
Sim[j,4] <- NA
}
}
}






#Date: May 2020

############# Testing Lines ################

grep -v "#" Sim.g.vcf > Sim.test.vcf
head Sim.test.vcf

#Prints the columns in order
grep -v "#" Sim.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | tail
#Save that
grep -v "#" Sim.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' > Sim.test.vcf


wc -l Sim.g.vcf
7046542 Sim.g.vcf
wc -l Sim.test.vcf
6868878 Sim.test.vcf

grep "1/1" Sim.test.vcf | wc -l

#get both phased and unphased
grep "1/1\|1|1" Sim.test.vcf | wc -l   
		410182 = 1/1 + 1|1


	0/0 		5,900,698
	1/1			172045
	0/1			280143
	1/0			0
	0|0			18462 (?)
	1|1			238137

#I CAN include that phased BUT all the phased have an additional phase/genotype on the same
#	line that is 1|0 so they are not really homozygous. Could be an artifact of the process
#	but better to not include them I think.

#Filter by quality

grep "1/1\|1|1" Sim.test.vcf | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | head 

#Is filtering by Q >100 doing anything?
grep "1/1" Sim.test.vcf | wc -l
172045

grep "1/1" Sim.test.vcf | awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' | wc -l
151190

#Yes filtering by Quality is doing something

awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' Sim.filtered2.vcf | head
awk -F "," '{if($3>100) {print} }' Sim.filtered2.vcf | awk '{{print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1}}' > Sim.filtered3.vcf


#Filter against the Solidissima Lines
#Prepare Solidissima, looking for anything that is different from the reference.
#Why would there even be 0/0s? <- Bad reads?
#We do not want to filter anything out
grep -v "#" Sol.g.vcf | awk '{ {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' > Sol.test.vcf 

#DONT PRINT IN FANCY ORDER
grep -v "#" Sol.g.vcf > Sol.test.vcf 

#Compare the two based on position. 
#Try using new program: Bedtools

export PATH=/programs/bedtools2-2.29.2/bin:$PATH
#Bedtools is expecting integer values for chromosomes

#Starting in R
/programs//R-3.5.0s/bin/R
install.packages("tidyverse")
library("tidyverse")
#install.packages("vcfR") #May not be needed
Sol <- read.table("Sol.test.vcf")
Sim <- read.table("Sim.filter.vcf")

> nrow(Sol)
[1] 3,833,767
> nrow(Sim)
[1] 151,190

Sol <- as.data.frame(Sol)
Sim <- as.data.frame(Sim)
#Chromosome (column 1 has a lot of extra data in it "Levels" but it does not affect what
I am doing here)

#Time this takes to run before its ecen doing anything: more than 5 minutes
#Took 4 minutes running on 18 threads
#How to get R to run on multiple CPU
for (i in 1:nrow(Sol)) {chrom <- Sol[i,1]
pos <- Sol[i,2]}

#Prior to starting R do the following:
export OMP_NUM_THREADS=16

#So quit R with q() and then that and then restart and do:
/programs//R-3.5.0s/bin/R
library("tidyverse")
Sol <- read.table("Sol.test.vcf")
Sim <- read.table("Sim.filter.vcf")
Sim["V11"] = "P"

#Test
for (i in 1:100) {
chrom <- Sol[i,1]
pos <- Sol[i,2]
for (j in 1:100) {
if (Sim[j,1]==chrom & Sim[j,2]==pos) {
Sim[j,4] <- NA
}
}
}

for (i in 1:nrow(Sol)) {
chrom <- Sol[i,1]
pos <- Sol[i,2]
if (check.integer(i/10000)) {print(i)}
for (j in 1:nrow(Sim)) {
if (Sim[j,1]==chrom & Sim[j,2]==pos) {
Sim[j,4] <- NA
print(Sim[j,4])
}
}
}

check.integer <- function(N){
    !grepl("[^[:digit:]]", format(N,  digits = 20, scientific = FALSE))
}

#Said that trying to insert "F" didn't work so I just put in NA
#Piping with >%> doesn't seem to work
#Doesn't look like its running on 16, but only 4 are available so I think/hope it was
#Next time insert a progress checker:
if (is.integer(i/10000)) {print(i)}
#and
print(Sim[j,4]) #after turning it NA





#Date: April 2020
#Code for filtering
grep "#" Sim.g.vcf > Sim.test.vcf
grep -v "#" Sim.subset.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' | tail
wc -l Sim.g.vcf
7,046,542 Sim.g.vcf
wc -l Sim.testplus.vcf 
6868878 Sim.testplus.vcf
Remove from grep #
grep -v "#" Sim.g.vcf | awk '{ {print $10,$1,$2,$3,$4,$5,$6,$7,$8,$9} }' > Sim.testplus.vcf
-v is remove
Sometimes is it 0|0? Yes. What is the difference between / and |, phased vs unphased
grep "0/0" Sim.testplus.vcf | wc -l
5900698
wc -l Sim.filtered3.vcf
5,169,980 Sim.filtered3.vcf
grep "0|0" Sim.testplus.vcf | wc -l
18462
They are the different types of data. For simplicity, which is most similar to theirs 
from the powerpoint? The first kind.
# SHOULD IT BE 1/1? YES
grep "0/0" Sim.testplus.vcf > Sim.filtered2.vcf
awk '{if($3>100) {print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1} }' Sim.filtered2.vcf | head
awk -F "," '{if($3>100) {print} }' Sim.filtered2.vcf | awk '{{print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1}}' > Sim.filtered3.vcf
awk -F "," '{if($3>100) {print} }' Sim.filtered2.vcf | awk '{{print $2,$3,$4,$5,$6,$7,$8,$9,$10,$1}}' | head



Filter Sol with Sim pieces
awk '{print $1, $2}' Sim.filtered3.vcf | head
grep -v "#" Sim.g.vcf | awk '{{print}}' > Sol.testplus.vcf

awk '{print $1, $2}' Sim.filtered3.vcf > Sim.filter.index.vcf



#Sub2 Test
head Sol.testplus.vcf > Sol.sub2.vcf
awk '{print $1, $2}' Sim.filtered3.vcf | head > Sim.sub2.vcf


Sim.sub2.vcf | for i in $(cat); do
    echo "$i"
done

while IFS='' read -r LINE || [ -n "${LINE}" ]; do
    echo "${LINE}"
    grep "${LINE}" Sol.sub2.vcf | awk '{print}'
done < Sim.sub2.vcf 

while IFS='' read -r LINE || [ -n "${LINE}" ]; do
echo ${LINE}
echo ${LINE} | cut -d " " --f 1
echo ${LINE} | cut -d " " --f 2
echo a
echo b
awk '{if($1==a && $2==b) {print} }' Sol.sub2.vcf
done < Sim.sub2.vcf 


while IFS='' read -r LINE || [ -n "${LINE}" ]; do
echo ${LINE}
echo "${LINE}" | cut -d " " --f 1 > a.txt
echo "${LINE}" | cut -d " " --f 2 > b.txt
awk '{if($1== && $2==b.txt) {print} }' Sol.sub2.vcf
done < Sim.sub2.vcf 

while IFS='' read -r LINE || [ -n "${LINE}" ]; do
echo ${LINE}
cut -d " " --f 1 "${LINE}" 
cut -d " " --f 2 "${LINE}"
awk '{if($1== cut -d " " --f 1 "${LINE}"  && $2==cut -d " " --f 2 "${LINE}") {print} }' Sol.sub2.vcf
done < Sim.sub2.vcf 

